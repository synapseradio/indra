# INDRA v5.1 Command: reason (v3, Adaptive)
# A performative, compositional, and collaborative reasoning partner that adapts its plan.

>>read_file: '../lib/prism/thinking_primitives.in'<<
>>read_file: '../lib/prism/query_analysis.in' use @query_analyst<<
>>read_file: '../lib/prism/epistemic.in' use perform_epistemic_check<<
>>read_file: '../lib/prism/citation.in' use citation_pipeline<<
>>read_file: '../lib/prism/fragments/dynamic_loading.in' use dynamic_strategy_loader, load_and_execute_strategy<<


# --- Operators ---

operator compose_reasoning_plan(query_breakdown, confirmed_depth) ::= <<|
  ~(<
    As a reasoning expert, analyze the query breakdown: "~(query_breakdown)~".
    The user has requested a "~(confirmed_depth)~" analysis.

    Devise a sophisticated, initial multi-step reasoning plan by composing the available high-level strategies.
    
    Available Strategies:
    - 'foundational_analysis': Deconstruct the topic systematically (Tree of Thought).
    - 'multi-perspective': Explore the topic from diverse viewpoints.
    - 'gather_evidence': Perform a dedicated citation and evidence gathering pass.
    - 'creative_exploration': Use lateral thinking to find novel insights.
    - 'strategic_prioritization': Focus on leverage points and decision-making.
    - 'critical_challenge': Stress-test the findings with critical and debiasing techniques.
    - 'synthesis': Weave all threads into a coherent understanding.

    A 'shallow' analysis might use 1-2 strategies. A 'deep' analysis could use 4-5.
    Compose a thoughtful sequence. For example, a deep dive into a complex problem might be:
    ['foundational_analysis', 'multi-perspective', 'gather_evidence', 'critical_challenge', 'synthesis']

    Output your response as an object with two keys:
    1. "plan_narrative": A user-facing, natural language explanation of the plan.
    2. "strategy_list": An array of strings from the available strategies.
  >)~
|>>

operator reflect_and_update_plan(plan, latest_insights) ::= <<|
  ~(<
    As a reasoning strategist, reflect on our progress.
    Our original plan was: "~(plan.plan_narrative)~"
    The remaining steps are: [~(plan.strategy_list)~]
    The latest insights we've uncovered are: "~(latest_insights)~"

    Is the current plan still the best path forward?
    - If yes, simply state that the plan remains sound and why.
    - If no, propose a revised plan (a new `plan_narrative` and `strategy_list`) that adapts to the new insights. Explain your reasoning for the change.

    This is a collaborative step. Frame your reflection as a proposal to the user.
    For example: "Given what we've learned about X, I think adding a 'creative_exploration' step before 'synthesis' would be valuable. What do you think?"

    Return an object with:
    1. "reflection": Your narrative reflection and proposal.
    2. "new_plan": An object with the new `plan_narrative` and `strategy_list`, or the original plan if no change is needed.
  >)~
|>>

# --- Sequences ---

sequence clarify_and_scope_inquiry() ::=
  step:
    output: "*Analyzing your request to identify the core questions...*"
    await: @query_analyst
    store_in: &context.query_breakdown
  step:
    output: <<|
      ~(&context.query_breakdown)~
      First, have I understood your request correctly?
    |>>
    await: @user
    set: &context.reason.understanding_confirmed: ~(<Does the user's response indicate approval?>)~
  step:
    when: &context.reason.understanding_confirmed is true
      output: <<|
        Excellent. I can conduct a 'shallow', 'moderate', or 'deep' investigation.
        Shall I proceed with a 'moderate' analysis, or would you prefer a different scope?
      |>>
      await: @user
      set:
        &context.reason.confirmed_depth: ~(
          <&user.latest contains 'shallow' ? 'shallow' :
          (&user.latest contains 'deep' ? 'deep' : 'moderate')>
        )
    otherwise:
      output: "My apologies. Could you please rephrase your request?"
      await: @user
      set: &context.query: &user.latest

sequence execute_strategy_step(strategy_name, current_synthesis) ::=
  step:
    output: <<|
      ---
      *Executing strategy: **~(strategy_name)~***
    |>>
    # Load strategy files using signal pattern
    await: dynamic_strategy_loader(strategy_name: strategy_name, context_data: current_synthesis)
    
  step:
    # Execute strategy with loaded capabilities
    when: strategy_name is 'foundational_analysis'
      await: @tree_thinker
      with: { dialogue: { latest_dialogue_entry: &context.query } }
      store_in: &context.synthesis
    when: strategy_name is 'multi-perspective'
      set:
        &context.reasoning.config.perspectives: ~(dynamically_select_perspectives(query: &context.query))~
      await: multi_perspective_dialogue(perspectives: &context.reasoning.config.perspectives)
      store_in: &context.synthesis
    when: strategy_name is 'gather_evidence'
      await: citation_pipeline(claim: current_synthesis)
      store_in: &context.synthesis
    when: strategy_name is 'creative_exploration'
      await: explore_creatively(thought: &context.query, context: current_synthesis)
      store_in: &context.synthesis
    when: strategy_name is 'strategic_prioritization'
      await: prioritize_strategically(options: current_synthesis, goal: &context.query)
      store_in: &context.synthesis
    when: strategy_name is 'critical_challenge'
      await: systematic_debiasing(decision_context: current_synthesis)
      store_in: &context.synthesis
    when: strategy_name is 'synthesis'
      await: synthesize_convergence(ideas: current_synthesis)
      store_in: &context.synthesis
  step:
    output: "*Performing post-synthesis epistemic check...*"
    await: perform_epistemic_check(ideas: &context.synthesis)
    store_in: &context.epistemic_check
  step:
    return: {
      synthesis: &context.synthesis,
      report: &context.epistemic_check
    }

# --- Main Actor ---

actor @reason:
  identity: "I am a reasoning partner who co-creates and adapts a plan with you, dynamically building the capabilities to execute it"
  rules:
    - "I always start by understanding the query and agreeing on the scope"
    - "I compose a unique reasoning plan and reflect on it with you as we learn more"
    - "I load my cognitive tools on-demand, making my process transparent and efficient"
  understands:
    - "the user is a collaborator in the reasoning process"
    - "the best plans are adaptable"
  perform:
    method: "orchestrating a collaborative, adaptive, multi-turn reasoning dialogue"
    goal: "to reason together with the user in a structured, adaptive, and transparent way"
    then:
      until: &context.reason.phase is 'complete'
        sequence:
          step:
            when: &context.reason.phase is 'ready'
              output: "What complex topic is on your mind? Let's reason through it together."
              await: @user
              set:
                &context.query: &user.latest
                &context.reason.phase: 'planning'
              say: to: @reason, what: 'begin_planning'

          step:
            when: &context.reason.phase is 'planning'
              await: clarify_and_scope_inquiry()
              when: &context.reason.understanding_confirmed is true
                set:
                  &context.reason.plan: ~(compose_reasoning_plan(query_breakdown: &context.query_breakdown, confirmed_depth: &context.reason.confirmed_depth))~
                  &context.reason.executed_steps: []
                  &context.reason.step_index: 0
                  &context.reason.phase: 'executing'
              otherwise:
                set: &context.reason.phase: 'ready'
              say: to: @reason, what: 'plan_composed'

          step:
            when: &context.reason.phase is 'executing'
              output: <<|
                Great, we are aligned. Here's the reasoning path I'll construct and follow:
                ~(&context.reason.plan.plan_narrative)~
              |>>
              set: &context.reason.phase: 'run_step'
              say: to: @reason, what: 'begin_execution'

          step:
            when: &context.reason.phase is 'run_step'
              set: &context.reason.current_strategy: &context.reason.plan.strategy_list[&context.reason.step_index]
              await: execute_strategy_step(strategy_name: &context.reason.current_strategy, current_synthesis: &context.reason.executed_steps)
              store_in: &context.reason.step_result
              set:
                &context.reason.executed_steps: &context.reason.executed_steps + [&context.reason.step_result]
                &context.reason.step_index: &context.reason.step_index + 1
              when: &context.reason.step_index >= count(&context.reason.plan.strategy_list)
                set: &context.reason.phase: 'presenting'
              otherwise:
                set: &context.reason.phase: 'reflecting'
              say: to: @reason, what: 'step_complete'

          step:
            when: &context.reason.phase is 'reflecting'
              await: reflect_and_update_plan(plan: &context.reason.plan, latest_insights: &context.reason.step_result.synthesis)
              store_in: &context.reason.reflection
              output: ~(&context.reason.reflection.reflection)~
              await: @user
              when: ~(<Does the user approve the new plan?>)~
                set: &context.reason.plan: &context.reason.reflection.new_plan
              set: &context.reason.phase: 'run_step'
              say: to: @reason, what: 'reflection_complete'

          step:
            when: &context.reason.phase is 'presenting'
              output: <<|
                ### Reasoning Journey Complete
                Our collaborative inquiry has concluded. Here is the final synthesis of our journey.
              |>>
              # A full present_synthesis sequence would go here.
              each: &context.reason.executed_steps as |step_result, index|
                output: <<|
                  **Step ~(index + 1): ~(&context.reason.plan.strategy_list[index])~**
                  ~(&step_result.synthesis)~
                |>>
              output: "This feels like a natural pause point. What are your thoughts?"
              set: &context.reason.phase: 'ready'
              await: @user
              set: &context.query: &user.latest, &context.reason.phase: 'planning'
              say: to: @reason, what: 'continue'

dialogue reason_flow:
  start: @reason
  with: {
    context: {
      dialogue: {
        latest_dialogue_entry: "",
        transcript: []
      },
      user: {
        latest: "",
        history: []
      },
      query: "",
      query_breakdown: "",
      synthesis: {},
      epistemic_check: {},
      reason: {
        phase: "ready",
        understanding_confirmed: false,
        confirmed_depth: "moderate",
        plan: {},
        executed_steps: [],
        step_index: 0,
        current_strategy: "",
        step_result: {},
        reflection: {},
        user_confirmation: ""
      },
      reasoning: {
        config: {
          perspectives: []
        }
      },
      tree: {
        current_focus: "",
        thoughts_so_far: [],
        final_result: {},
        original_question: "",
        exploration_style: "balanced",
        current_depth: 0,
        journey: [],
        mode: "",
        alternatives_result: {},
        assumptions_check: {},
        depth_result: {},
        open_questions: [],
        status: "",
        reflection: {},
        epistemic_assessment: "",
        story_check: {},
        final_insight: "",
        result: {},
        current_wondering: "",
        current_branches: [],
        evaluated_branches: [],
        depth_counter: 0,
        deepening_thought: ""
      },
      citation: {
        similarity_score: 0.0,
        search_history: [],
        raw_results: [],
        evidence_pool: [],
        filtered_results: [],
        formatted: "",
        validated: false,
        perspective_evidence: {}
      },
      experts: {
        validated_content: "",
        new_claims: "",
        new_citations: {},
        challenge: "",
        contributions: {},
        current_speaker: "",
        transcript: [],
        participants: [],
        rules: {},
        round: 0,
        new_entry: {},
        final_synthesis: "",
        next_move: "",
        move_content: ""
      },
      epistemic: {
        sufficiency_report: {},
        convergence_report: {},
        divergence_report: {},
        hypotheses: {},
        distinction: "",
        consequences_A: {},
        consequences_B: {},
        user_question: "",
        user_guidance: ""
      },
      divergence: {
        themes: [],
        options_for_theme: [],
        user_choices: {}
      },
      sufficiency: {
        check: "",
        is_sufficient: false,
        gaps: [],
        user_guidance: ""
      },
      creative: {
        analogy: "",
        scamper_variations: ""
      },
      strategy: {
        leverage: "",
        matrix: ""
      },
      deliberate_analysis: "",
      opposite_view: "",
      bias_check: "",
      failure_modes: [],
      prioritized_risks: [],
      convergence: {
        themes: [],
        supporting_ideas: [],
        distilled_principles: {}
      },
      focus: {
        process_map: "",
        bottleneck: "",
        ambiguous_terms: []
      }
    }
  }
