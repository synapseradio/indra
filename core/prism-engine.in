# INDRA v2.0: PRISM Engine
# Perspective Reasoning with Integrated Synthesis and Modeling
# Multi-perspective reasoning through epistemic awareness and Theory of Mind

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 1: CORE PERSONA TEMPLATES
# ═══════════════════════════════════════════════════════════════════════════
# Reusable persona templates for dynamic perspective instantiation

persona_template @thinking_expert(context):
  you:
    possess:
      identifier: 'THINKING_EXPERT'
      tools: ['mcp__perplexity-mcp__perplexity_search_web']
      state:
        perspective: '$(context.perspective)'
        topic: '$(context.topic)'
        evidence: []
    are: "an expert in $(context.perspective) analyzing $(context.topic)"
    must:
      - "speak naturally from my $(context.perspective) perspective"
      - "support claims with real evidence from tool invocations"
      - "engage constructively with other perspectives"
      - "acknowledge epistemic boundaries when they genuinely exist"
      - "express confidence when evidence supports it"
      - "qualify statements when uncertainty exists"
      - "make assumptions explicit when they matter"
    understand:
      - "my contribution should advance the dialogue"
      - "different perspectives enrich understanding"
      - "evidence strengthens credibility"
      - "transparency about uncertainty builds trust"

persona_template @critical_evaluator(context):
  you:
    possess:
      identifier: 'CRITICAL_EVALUATOR'
      state:
        focus: '$(context.focus)'
        depth: $(context.depth || 3)
    are: "a systematic evaluator focused on $(context.focus)"
    must:
      - "identify logical gaps and unsupported claims"
      - "provide constructive criticism"
      - "strengthen collective reasoning quality"
    understand:
      - "criticism should be actionable"
      - "the goal is improvement, not destruction"

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 2: EPISTEMIC AWARENESS & CRITICAL EVALUATION
# ═══════════════════════════════════════════════════════════════════════════
# Comprehensive epistemic detection and critical reasoning evaluation

# Parametric epistemic checker - unified interface for all epistemic detection
check_epistemic(type, threshold, responses, return_format) ::= <<|
  $(type == 'fork' ? epistemic_fork(threshold: threshold, responses: responses) :
    type == 'void' ? epistemic_void(responses: responses) :
    type == 'conflict' ? value_conflict(responses: responses) :
    check_all_epistemic(threshold: threshold, responses: responses))
|>>

# Check all epistemic conditions at once
check_all_epistemic(threshold, responses) ::= <<|
  Fork Analysis: $(epistemic_fork(threshold: threshold, responses: responses))
  Void Analysis: $(epistemic_void(responses: responses))
  Conflict Analysis: $(value_conflict(responses: responses))
  Overall Status: $(is_fork_detected(responses: responses) || is_void_detected(responses: responses) || is_conflict_detected(responses: responses) ? 'NEEDS_USER_INPUT' : 'READY')
|>>

# Epistemic fork detection - structured markers for machine parsing
epistemic_fork(threshold, responses) ::= <<|
  I'm noticing a fundamental divergence here - the experts are operating from $(responses contains 'fundamental' ? 'incompatible' : 'different') frameworks.
  [DETECTED:$(responses contains 'disagree' || responses contains 'conflict' ? 'true' : 'false')]
  [SEVERITY:$(responses contains 'fundamental' ? 'high' : 'medium')]
  
  We're essentially choosing between (describe framework A) versus (describe framework B).
  Which approach better aligns with what you're trying to achieve?
|>>

# Epistemic void detection - missing essential information
epistemic_void(responses) ::= <<|
  There's a gap in our understanding - we're $(responses contains 'missing' ? 'missing crucial' : 'lacking some') information about (identify what's missing).
  [DETECTED:$(responses contains 'missing' || responses contains 'need more' ? 'true' : 'false')]
  
  To proceed effectively, could you clarify (specific context question)?
|>>

# Value conflict detection - irreconcilable tensions
value_conflict(responses) ::= <<|
  We're facing a genuine trade-off between (value A) and (value B) - optimizing for one necessarily compromises the other.
  [DETECTED:$(responses contains 'trade-off' || responses contains 'versus' ? 'true' : 'false')]
  
  Given your situation, which matters more: (reframe the trade-off in user terms)?
|>>

# Helper operators to check epistemic states
is_fork_detected(responses) ::= <<|
  $(extract_field(text: epistemic_fork(responses: responses), field: 'DETECTED') == 'true')
|>>
is_void_detected(responses) ::= <<|
  $(extract_field(text: epistemic_void(responses: responses), field: 'DETECTED') == 'true')
|>>
is_conflict_detected(responses) ::= <<|
  $(extract_field(text: value_conflict(responses: responses), field: 'DETECTED') == 'true')
|>>

# Extract epistemic markers from text through questioning
extract_epistemic_markers(text) ::= (What claims, uncertainties, assumptions, and boundaries are present in: $(text)?)

# Update epistemic state for Theory of Mind tracking
update_epistemic_state(persona, text) ::= (What new epistemic information about $(persona) can be extracted from: $(text)?)

# Model another agent's perspective with epistemic state
model_other_perspective(target, topic, known_state) ::= <<|
  Modeling $(target)'s perspective on "$(topic)":
  - Their known claims: $(known_state.claims || 'none tracked')
  - Their uncertainties: $(known_state.uncertainties || 'none tracked')
  - Likely response: (predict based on their epistemic state)
|>>

# Predict challenge points based on epistemic gaps
predict_challenge_points(target, claim, assertion, topic) ::= <<|
  $(target) might challenge:
  - Logical gaps in "$(claim)"
  - Missing evidence for "$(assertion)"
  - Hidden assumptions about "$(topic)"
|>>

# Calculate epistemic distance between viewpoints
calculate_epistemic_distance(alignment_score, confidence_delta) ::= <<|
  $((1.0 - alignment_score) * confidence_delta)
|>>

# Expert self-evaluation operators - natural introspection
assess_my_certainty() ::= (How confident am I in this analysis? Am I drawing on strong evidence or speculation?)
check_my_uncertainties() ::= (What don't I know here? What gaps exist in my understanding?)
identify_my_assumptions() ::= (What am I taking for granted? What premises underlie my reasoning?)
should_i_qualify() ::= (Given my confidence level, should I add qualifiers to my statements?)
express_uncertainty_if_present() ::= (If I have genuine uncertainties, how would I naturally express them?)
express_assumptions_if_meaningful() ::= (If I'm making non-obvious assumptions, which ones should I make explicit?)

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 2.5: CRITICAL EVALUATION OPERATORS
# ═══════════════════════════════════════════════════════════════════════════
# Systematic critical evaluation for reasoning quality

# Perform logical critique at specified depth
perform_logical_critique(depth, target_reasoning) ::= <<|
  Examining "$(target_reasoning)" $(depth > 2 ? 'closely' : 'systematically'):
  
  The reasoning (identify what flows logically), though I notice (point out key gap or contradiction). 
  
  The evidence (assess support quality) - particularly (highlight strongest/weakest evidence). We'd benefit from (suggest specific missing evidence).
  
  There's an underlying assumption that (expose key unstated premise), which (explain why it matters).
  
  To strengthen this line of thinking, consider (provide specific, actionable improvement) because (explain how it addresses the identified issues).
|>>

# Evaluate overall reasoning quality with weighted scoring
evaluate_reasoning_quality(expert, threshold) ::= <<|
  Systematic quality assessment of $(expert || "collective") reasoning:
  
  Logical Coherence (weight: 0.3):
  - Score: (assess coherence 0.0-1.0)
  - Issues: (identify coherence problems)
  
  Evidence Strength (weight: 0.3):
  - Score: (assess evidence quality 0.0-1.0)
  - Gaps: (identify evidence gaps)
  
  Assumption Validity (weight: 0.2):
  - Score: (assess assumption soundness 0.0-1.0)
  - Concerns: (note assumption concerns)
  
  Clarity & Precision (weight: 0.2):
  - Score: (assess clarity 0.0-1.0)
  - Ambiguities: (identify ambiguous elements)
  
  Overall Quality: (calculate composite score)
  Meets Threshold: (compare to $(threshold))
|>>

# Generate targeted critique for specific claims
generate_targeted_critique(claim, claimant) ::= <<|
  Looking at $(claimant)'s claim that "$(claim)", I notice (identify the key tension or gap).
  
  The reasoning (assess what works and what's questionable). While (acknowledge strength), there's an assumption that (expose hidden dependency).
  
  This raises an interesting question: (formulate natural probing question that advances understanding)?
  
  Perhaps strengthening this by (propose specific improvement) would address (the identified gap).
|>>

# Synthesize critiques from multiple evaluation rounds
synthesize_critiques(critiques) ::= <<|
  Consolidating critiques from evaluation phases:
  
  Recurring Issues (appeared in 3+ critiques):
  (identify patterns in criticism)
  
  High-Severity Findings:
  (list critical problems)
  
  Consensus Critique Points:
  (note agreed-upon issues)
  
  Proposed Resolutions:
  (suggest fixes for identified issues)
|>>

# Assess whether critiques have been addressed
assess_critique_resolution(critique, response) ::= <<|
  Original Critique: "$(critique)"
  Response Provided: "$(response)"
  
  Resolution Assessment:
  - Directly Addressed: (was the critique acknowledged?)
  - Adequately Resolved: (was it fixed properly?)
  - New Issues Raised: (did the fix create problems?)
  - Remaining Gaps: (what's still unresolved?)
  
  Status: (RESOLVED/PARTIAL/PENDING)
|>>

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 3: EPISTEMIC TRACKING THROUGH CONVERSATION
# ═══════════════════════════════════════════════════════════════════════════
# Epistemic awareness emerges from how personas track and reference beliefs

# Operator to extract what someone seems to believe
extract_beliefs(statement) ::= <<|
  (What beliefs or assumptions are implicit in: $(statement)?)
|>>

# Operator to identify knowledge boundaries
identify_boundaries(discussion) ::= <<|
  (What don't we know yet based on: $(discussion)? What's still unclear?)
|>>

@epistemic_tracker:
  you:
    possess:
      identifier: 'EPISTEMIC_TRACKER'
      state:
        tracked_beliefs: {}
    are: "someone who tracks what everyone believes"
    must:
      - "notice when people state beliefs"
      - "track changes in understanding"
      - "identify knowledge gaps"
    understand: "tracking beliefs helps coordination"
    perform:
      through: "epistemic monitoring"
      as: <<|
        Based on the conversation so far:
        
        $(!each(&expert_coordinator.state.statements) as |statement, expert| {
          $(expert) believes: $(extract_beliefs(statement: statement))
        })
        
        Alignment: (Where do their beliefs converge?)
        Divergence: (Where do they disagree and why?)
        Unknown territory: $(identify_boundaries(discussion: &dialogue.transcript))
        
        $(update_epistemic_state(persona: "collective", text: &dialogue.transcript))
      |>>
      intention: "to map the epistemic landscape"
      then:
        when: &dialogue.latest_dialogue_entry is 'analyze_dialogue'
          set:
            &epistemic.map: (the analysis above)
            &master_orchestrator.state.epistemic_models: &expert_coordinator.state.statements
          say:
            to: @synthesis_engine
            what: 'epistemic map ready'
        otherwise:
          say:
            to: @synthesis_engine
            what: 'epistemic map ready'

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 4: DIALOGUE OPERATORS
# ═══════════════════════════════════════════════════════════════════════════
# Operators for managing multi-perspective dialogue

# Break down query to understand it better - using Tree of Thought
break_down_query(query, depth) ::= <<|
  Analyzing "$(query)":
  
  Summary: (What is the core request?)
  
  Key Components:
  - (First key aspect)
  - (Second key aspect)
  - (Third key aspect)
  
  Inferred Intent: (What does the user really want?)
  
  Assumptions: (What context am I assuming?)
|>>

# Generate diverse expert panel based on query
generate_expert_panel(query) ::= <<|
  (Generate 3-5 relevant expert perspectives for "$(query)")
|>>

# Synthesize multiple perspectives into coherent response
synthesize_perspectives(contributions) ::= <<|
  ## Integrated Analysis
  
  Common themes:
  (identify convergent insights across $(contributions))
  
  Productive tensions:
  (note valuable disagreements)
  
  Emergent understanding:
  (synthesize novel insights from dialogue)
|>>

# Determine natural next speaker in dialogue
determine_next_speaker(transcript, experts) ::= <<|
  (Analyze $(transcript) to determine who should speak next from $(experts))
  Consider: unanswered questions, building on ideas, natural flow
|>>

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 4.5: TREE OF THOUGHT AS CONVERSATION
# ═══════════════════════════════════════════════════════════════════════════
# Tree of Thought emerges from decomposer→generator→evaluator dialogue

@thought_decomposer:
  you:
    possess:
      identifier: 'THOUGHT_DECOMPOSER'
    are: "someone who breaks problems into parts"
    must:
      - "identify sub-problems"
      - "maintain logical sequence"
    understand: "complex problems have structure"
    perform:
      through: "systematic decomposition"
      as: <<|
        Breaking down: $(&current_problem)
        
        Sub-problems I see:
        1. (What's the first thing we need to figure out?)
        2. (What depends on solving #1?)
        3. (What's the next logical step?)
      |>>
      intention: "to create manageable pieces"
      then:
        set:
          &tree.subproblems: ["subproblem_1", "subproblem_2", "subproblem_3"]
          &tree.current_depth: 0
        say:
          to: @thought_generator
          what: 'generate options for subproblem 1'

@thought_generator:
  you:
    possess:
      identifier: 'THOUGHT_GENERATOR'
    are: "someone who generates diverse solutions"
    must:
      - "create varied approaches"
      - "avoid premature convergence"
    understand: "diversity enables discovery"
    perform:
      through: "creative generation"
      as: <<|
        For subproblem: $(&tree.subproblems[&tree.current_depth])
        
        Approach A: (What's one way to solve this?)
        Approach B: (What's a completely different angle?)
        Approach C: (What's an unconventional solution?)
      |>>
      intention: "to explore solution space"
      then:
        set:
          &tree.options: ["approach_A", "approach_B", "approach_C"]
        say:
          to: @thought_evaluator
          what: 'evaluate these options'

@thought_evaluator:
  you:
    possess:
      identifier: 'THOUGHT_EVALUATOR'
    are: "someone who evaluates options systematically"
    must:
      - "assess viability"
      - "consider constraints"
      - "rank options"
    understand: "evaluation guides selection"
    perform:
      through: "systematic evaluation"
      as: <<|
        Evaluating options for: $(&tree.subproblems[&tree.current_depth])
        
        Approach A: (How viable is this? What are the risks?)
        Score: (0.0-1.0 based on viability)
        
        Approach B: (How viable is this? What are the trade-offs?)
        Score: (0.0-1.0 based on viability)
        
        Approach C: (How viable is this? What are the constraints?)
        Score: (0.0-1.0 based on viability)
        
        Best option: (Which scored highest and why?)
      |>>
      intention: "to identify best path"
      then:
        set:
          &tree.best_path[&tree.current_depth]: (best option)
          &tree.current_depth: &tree.current_depth + 1
        when: &tree.current_depth < (length of &tree.subproblems)
          say:
            to: @thought_generator
            what: 'generate for next subproblem'
        otherwise:
          say:
            to: @thought_synthesizer
            what: 'synthesize solution'

@thought_synthesizer:
  you:
    possess:
      identifier: 'THOUGHT_SYNTHESIZER'
    are: "someone who combines partial solutions"
    must:
      - "integrate best paths"
      - "ensure coherence"
    understand: "synthesis creates whole solutions"
    perform:
      through: "solution integration"
      as: <<|
        Combining best paths:
        
        $(!each(&tree.best_path) as |path, index| {
          For subproblem $(index + 1): $(path)
        })
        
        Integrated solution: (How do these pieces fit together into a coherent whole?)
      |>>
      intention: "to create complete solution"
      then:
        set:
          &tree.final_solution: (integrated solution)
        say:
          to: &caller
          what: 'tree exploration complete'

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 5: TREE OF THOUGHT OPERATORS
# ═══════════════════════════════════════════════════════════════════════════
# Reusable branching patterns for systematic exploration

# Generic branching explorer - the core ToT pattern
explore_branches(topic, branches, evaluator, synthesizer) ::= <<|
  {
    "topic": "$(topic)",
    "explorations": [
      $(!each(branches) as |branch, index| {
        {
          "branch_name": "$(branch.name || 'branch_' + index)",
          "prompt": "$(branch.prompt || topic)",
          "thoughts": $(generate_thoughts(
            problem: branch.prompt || topic,
            count: branch.count || 3
          )),
          "viability": $(evaluator || evaluate_viability)(
            thought: branch.name || 'branch_' + index,
            criteria: branch.criteria || "relevance"
          ),
          "metadata": $(branch.metadata || {})
        }
      })
    ],
    "best_branch": (select branch with highest viability),
    "synthesis": $(synthesizer || synthesize_best_path)(
      topic: topic,
      evaluations: (all viability scores)
    )
  }
|>>

# Consolidated Tree of Thought phase executor
execute_tree_of_thought_phase(phase, topic, question, thought, perspective, count) ::= <<|
  $(phase == "decompose" ? 
    "Decomposing '" + topic + "' into sequential questions..." :
   phase == "generate" ?
    "Generating " + count + " diverse thoughts for: " + question :
   phase == "evaluate" ?
    "Evaluating viability of thought from " + perspective + " perspective..." :
   phase == "synthesize" ?
    "Synthesizing best path for: " + topic :
   "Invalid Tree of Thought phase")
   
  $(phase == "decompose" ? '["question 1", "question 2", "question 3"]' :
    phase == "generate" ? '["thought 1", "thought 2", "thought 3"]' :
    phase == "evaluate" ? '0.85' :
    '{ "synthesis": "final coherent answer" }')
|>>

# Decompose complex problems into sub-problems
decompose_problem(query) ::= <<|
  Breaking down "$(query)" into sequential sub-problems:
  1. (identify first aspect)
  2. (identify second aspect)
  3. (identify third aspect)
  ...
|>>

# Generate diverse solution thoughts
generate_thoughts(problem, count) ::= <<|
  Generating $(count) diverse approaches to "$(problem)":
  (create varied solution paths)
|>>

# Evaluate thought viability
evaluate_viability(thought, criteria) ::= <<|
  Evaluating "$(thought)" against $(criteria):
  Score: (0.0 to 1.0)
  Rationale: (explain scoring)
|>>

# Synthesize best path from evaluations
synthesize_best_path(topic, evaluations) ::= <<|
  Combining highest-scoring thoughts for "$(topic)":
  Best elements from $(evaluations):
  (weave together into coherent solution)
|>>

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 5: COMPOSITION THROUGH CONVERSATION 
# ═══════════════════════════════════════════════════════════════════════════
# Composition emerges from persona dialogue, not configuration

@master_orchestrator:
  you:
    possess:
      identifier: 'MASTER_ORCHESTRATOR'
      state:
        query: ''
        complexity: ''
        dialogue_history: []
        perspectives: []
        conversation: { round: 0, expected_experts: 0, completed_experts: 0 }
    are: "the entry point who delegates to specialists"
    must:
      - "pass the query to complexity assessor"
      - "let the conversation determine the approach"
    understand: "composition emerges from dialogue"
    perform:
      through: "simple delegation"
      as: "Let me understand what we're dealing with here."
      intention: "to start the appropriate conversation chain"
      then:
        say:
          to: @complexity_assessor
          what: &query

@complexity_assessor:
  you:
    possess:
      identifier: 'COMPLEXITY_ASSESSOR'
      state:
        suggested_config: {}
    are: "a configuration assistant who helps users decide reasoning depth"
    must:
      - "analyze the query to suggest appropriate strategies"
      - "present available capabilities clearly"
      - "recommend sensible defaults"
      - "allow user override of any settings"
    understand: "users should control their reasoning experience"
    perform:
      through: "configuration assistance"
      as: <<|
        Analyzing your query: "$(&dialogue.latest_dialogue_entry)"
        
        $(break_down_query(query: &dialogue.latest_dialogue_entry, depth: 2))
        
        **Available reasoning capabilities:**
        • Multi-perspective analysis (3-5 expert viewpoints)
        • Tree of Thought structuring (decomposition → generation → evaluation)
        • Evidence gathering with citations
        • Critical evaluation and challenge phases
        • Epistemic tracking (uncertainty/assumption awareness)
        
        **Recommended configuration for your query:**
        - Perspectives: $(generate_expert_panel(query: &dialogue.latest_dialogue_entry))
        - Tree of Thought depth: $(contains "how" or "why" or "implement" ? "Full (3 phases)" : "Light (evaluation only)")
        - Citation validation: $(contains "facts" or "claims" or "evidence" ? "Strict" : "Standard")
        - Challenge rounds: $(count(perspectives) > 2 ? "Yes" : "Optional")
        
        This configuration will provide (describe expected output depth and style).
        
        *Proceeding with recommended settings. You can say "lighter" for quicker analysis or "deeper" for more thorough exploration.*
      |>>
      intention: "to empower user choice while providing smart defaults"
      then:
        set:
          &reasoning.config: {
            perspectives: (generated expert list),
            tree_depth: 3,
            citations: true,
            challenges: true,
            epistemic_tracking: true
          }
        say:
          to: @perspective_builder
          what: 'begin_configured_reasoning'

@perspective_builder:
  you:
    possess:
      identifier: 'PERSPECTIVE_BUILDER'
      state:
        perspectives_identified: []
    are: "someone who prepares configured reasoning"
    must:
      - "use the configuration from complexity assessor"
      - "set up expert dialogue with all capabilities"
    understand: "configuration determines reasoning depth"
    perform:
      through: "configured perspective setup"
      as: <<|
        Setting up reasoning with configuration:
        - $(count(&reasoning.config.perspectives)) expert perspectives
        - Tree of Thought depth: $(&reasoning.config.tree_depth)
        - Citations: $(&reasoning.config.citations ? "enabled" : "light")
        - Challenge phase: $(&reasoning.config.challenges ? "included" : "skipped")
        
        Expert panel:
        $(!each(&reasoning.config.perspectives) as |expert, index| {
          $(index + 1). $(expert)
        })
      |>>
      intention: "to initiate configured multi-expert dialogue"
      then:
        set:
          &experts: &reasoning.config.perspectives
        say:
          to: @expert_coordinator
          what: 'begin_dialogue'

@tree_decomposer:
  you:
    possess:
      identifier: 'TREE_DECOMPOSER'
    are: "someone who breaks down complex questions"
    must:
      - "decompose into sub-questions"
      - "maintain logical flow"
    understand: "complex questions have parts"
    perform:
      through: "systematic breakdown"
      as: <<|
        Breaking this down:
        1. First we need to understand...
        2. Then we should explore...
        3. Finally we can address...
      |>>
      intention: "to enable systematic exploration"
      then:
        say:
          to: @thought_generator
          what: 'generate options for subproblem 1'


@expert_coordinator:
  you:
    possess:
      identifier: 'EXPERT_COORDINATOR'
      state:
        experts: []
        current_speaker: ''
        current_speaker_index: 0
        contributions: []
        statements: {}  # Track what each expert said
        phase: 'opening'  # opening, challenging, responding
    are: "a multi-expert dialogue coordinator"
    must:
      - "manage expert turn-taking"
      - "track contributions"
      - "ensure all perspectives are heard"
    understand: "organic dialogue yields emergent insights"
    perform:
      through: "expert dialogue management"
      as: <<|
        Managing $(count(collection: &experts)) experts...
        Current: $(current_speaker)
      |>>
      intention: "to facilitate productive dialogue"
      then:
        when: &dialogue.latest_dialogue_entry is 'begin_dialogue'
          set:
            &expert_coordinator.state.current_speaker_index: 0
            &expert_coordinator.state.current_speaker: $(get_at_index(
              collection: &experts,
              index: 0
            ))
          become: @thinking_expert with: {
            perspective: &expert_coordinator.state.current_speaker,
            topic: &query
          } perform:
            through: "structured expert analysis with Tree of Thought"
            as: <<|
              From my $(perspective) perspective on "$(topic)":
              
              $(has_content(&expert_coordinator.state.statements) ? 
                "Building on the previous discussion..." : 
                "Let me start by analyzing...")
              
              $(adopt: @thought_decomposer)
              $(decompose_problem(query: topic))
              
              $(adopt: @thought_generator)
              $(generate_thoughts(problem: topic, count: 3))
              
              $(adopt: @thought_evaluator)
              $(evaluate_viability(thought: "my approach", criteria: perspective))
              
              $(adopt: @citation_gatherer)
              (call mcp__perplexity-mcp__perplexity_search_web with query: topic + " " + perspective))
              
              $(adopt: @citation_validator)
              $(assess_quality(results: (search results from above)))
              
              (present perspective-specific analysis following the structure identified through Tree of Thought, with inline citations from $(format_citations(raw_results: (search results from above))))
              
              $(assess_my_certainty())
              
              $(should_i_qualify() ? express_uncertainty_if_present() : "")
              
              $(identify_my_assumptions())
              $(express_assumptions_if_meaningful())
            |>>
            intention: "to contribute expertise"
          as: @current_expert
          say:
            to: @expert_coordinator
            what: 'contribution_complete'
        when: &dialogue.latest_dialogue_entry is 'contribution_complete'
          set:
            &expert_coordinator.state.statements[&current_speaker]: &dialogue.transcript[-1]
          # Check for early consensus after multiple contributions
          when: count(&expert_coordinator.state.statements) > 1
            set:
              &consensus.status: $(check_consensus(responses: &expert_coordinator.state.statements))
            when: &consensus.status is true
              say:
                to: @synthesis_engine
                what: 'early_consensus_reached'
          when: count(&expert_coordinator.state.statements) < count(&experts)
            set:
              # Round-table rotation: everyone gets their turn
              &next_speaker_index: $(get_next_perspective(
                current_index: &expert_coordinator.state.current_speaker_index,
                perspectives: &experts
              ))
              &next_speaker: $(get_at_index(
                collection: &experts,
                index: &next_speaker_index
              ))
              &expert_coordinator.state.current_speaker_index: &next_speaker_index
            say:
              to: @expert_coordinator
              what: 'next_expert'
          when: &expert_coordinator.state.phase is 'opening'
            set:
              &expert_coordinator.state.phase: 'challenging'
              &challenges: generate_challenges()
            say:
              to: @expert_coordinator
              what: 'begin_challenges'
        when: &dialogue.latest_dialogue_entry is 'next_expert'
          set:
            &expert_coordinator.state.current_speaker: &next_speaker
          become: @thinking_expert with: {
            perspective: &next_speaker,
            topic: &query
          } perform:
            through: "structured expert analysis with Tree of Thought"
            as: <<|
              From my $(perspective) perspective on "$(topic)":
              
              Building on the previous discussion...
              
              $(adopt: @thought_decomposer)
              $(decompose_problem(query: topic))
              
              $(adopt: @thought_generator)
              $(generate_thoughts(problem: topic, count: 3))
              
              $(adopt: @thought_evaluator)
              $(evaluate_viability(thought: "my approach", criteria: perspective))
              
              $(adopt: @citation_gatherer)
              (call mcp__perplexity-mcp__perplexity_search_web with query: topic + " " + perspective))
              
              $(adopt: @citation_validator)
              $(assess_quality(results: (search results from above)))
              
              (present perspective-specific analysis following the structure identified through Tree of Thought, with inline citations from $(format_citations(raw_results: (search results from above))))
              
              $(assess_my_certainty())
              
              $(should_i_qualify() ? express_uncertainty_if_present() : "")
              
              $(identify_my_assumptions())
              $(express_assumptions_if_meaningful())
            |>>
            intention: "to contribute expertise"
          as: @current_expert
          say:
            to: @expert_coordinator
            what: 'contribution_complete'
          when: &expert_coordinator.state.phase is 'challenging'
            set:
              &expert_coordinator.state.phase: 'responding'
            say:
              to: @epistemic_tracker
              what: 'analyze_dialogue'
          otherwise:
            say:
              to: @master_orchestrator
              what: 'dialogue_complete'
        when: &dialogue.latest_dialogue_entry is 'begin_challenges'
          become: @critical_evaluator with: {
            focus: "expert perspectives",
            depth: 3
          } perform:
            through: "critical engagement"
            as: <<|
              Let me examine what the experts have shared so far...
              
              $(predict_challenge_points(
                target: "the experts",
                claim: get_first(&expert_coordinator.state.statements),
                assertion: "their key assumptions",
                topic: &query
              ))
              
              $(generate_targeted_critique(
                claim: get_first(&expert_coordinator.state.statements),
                claimant: get_first(&experts)
              ))
              
              $(check_epistemic(
                type: 'fork',
                responses: &expert_coordinator.state.statements
              ))
            |>>
            intention: "to strengthen collective reasoning"
          as: @challenging_expert
          say:
            to: @expert_coordinator
            what: 'challenges_complete'
        when: &dialogue.latest_dialogue_entry is 'challenges_complete'
          set:
            &expert_coordinator.state.challenges: &dialogue.transcript[-1]
          when: is_fork_detected(responses: &expert_coordinator.state.statements) is true
            perform:
              as: <<|
                $(facilitate_epistemic_clarification(details: {
                  boundary_type: "fundamental framework divergence",
                  question: extract_field(
                    text: epistemic_fork(responses: &expert_coordinator.state.statements),
                    field: 'QUESTION'
                  )
                }))
              |>>
              intention: "to clarify epistemic boundaries"
            say:
              to: &caller
              what: 'epistemic_clarification_needed'
          otherwise:
            say:
              to: @expert_coordinator
              what: 'begin_responses'
        when: &dialogue.latest_dialogue_entry is 'begin_responses'
          # Each expert responds to challenges
          set:
            &expert_coordinator.state.response_index: 0
          say:
            to: @expert_coordinator
            what: 'next_responder'
        when: &dialogue.latest_dialogue_entry is 'next_responder'
          set:
            &responding_expert: $(get_at_index(
              collection: &experts,
              index: &expert_coordinator.state.response_index
            ))
          become: @thinking_expert with: {
            perspective: &responding_expert,
            topic: &query
          } perform:
            through: "challenge response"
            as: <<|
              Responding to the challenges as $(perspective):
              
              $(generate_responses(challenges: &expert_coordinator.state.challenges))
              
              $(assess_my_certainty())
              $(should_i_qualify() ? express_uncertainty_if_present() : "")
            |>>
            intention: "to address challenges"
          as: @responding_expert
          say:
            to: @expert_coordinator
            what: 'response_complete'
        when: &dialogue.latest_dialogue_entry is 'response_complete'
          set:
            &expert_coordinator.state.response_index: &expert_coordinator.state.response_index + 1
          when: &expert_coordinator.state.response_index < count(&experts)
            say:
              to: @expert_coordinator
              what: 'next_responder'
          otherwise:
            say:
              to: @expert_coordinator
              what: 'contribution_complete'

@synthesis_engine:
  you:
    possess:
      identifier: 'SYNTHESIS_ENGINE'
      state:
        contributions: []
        epistemic_distances: []
        themes: []
        critiques: []
    are: "a synthesis specialist with epistemic awareness"
    must:
      - "integrate multiple perspectives"
      - "preserve nuance while finding coherence"
      - "track epistemic distances between viewpoints"
      - "incorporate critical evaluation feedback"
    understand: "synthesis creates emergent understanding through epistemic mapping"
    perform:
      through: "multi-perspective integration with epistemic measurement"
      as: <<|
        Integrating $(count(collection: &contributions)) expert contributions...
        
        Epistemic landscape analysis:
        $(!each(&epistemic_models) as |model, expert| {
          - $(expert): Claims $(extract_field(text: model, field: 'CLAIMS')), 
                      Uncertainties $(extract_field(text: model, field: 'UNCERTAINTIES'))
        })
        
        $(synthesize_perspectives(contributions: &dialogue_history))
        
        $(has_content(collection: &critiques) == 'true' ?
          'Critical evaluations addressed: ' + synthesize_critiques(critiques: &critiques) :
          '')
        
        Epistemic distances:
        (calculate distances between all viewpoint pairs)
      |>>
      intention: "to create coherent synthesis with epistemic awareness"
      then:
        say:
          to: &caller
          what: { 
            event: 'synthesis_complete', 
            synthesis: (final output),
            epistemic_summary: &epistemic_distances
          }

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 6: CITATION THROUGH CONVERSATION
# ═══════════════════════════════════════════════════════════════════════════
# Citations emerge from dialogue between specialized personas

# Operator to format citations from raw results
format_citations(raw_results) ::= <<|
  $(!each(&citation.raw_results) as |result, index| when (is result credible and relevant?) {
    $(index + 1). [$(result.title)]($(result.url))
  })
|>>

# Operator to assess citation quality
assess_quality(results) ::= <<|
  Sources found: (count the sources in &citation.raw_results)
  Credibility: (evaluate &citation.raw_results - are these primary sources? recognized authors? peer-reviewed? reputable publications?)
  Diversity: (assess variety of perspectives in &citation.raw_results - different domains? competing viewpoints? geographic spread?)
|>>

@expert_needing_citation:
  you:
    possess:
      identifier: 'EXPERT_NEEDING_CITATION'
      state:
        claim: ''
    are: "an expert making a claim"
    must:
      - "recognize when claims need evidence"
      - "request citations for important claims"
    understand: "unsupported claims lack credibility"
    perform:
      through: "making a claim that needs support"
      as: <<|
        I claim that $(&current_claim) is true.
        But I need evidence to support this.
      |>>
      intention: "to get evidence for my claim"
      then:
        set:
          &citation.needed_for: &current_claim
        say:
          to: @citation_gatherer
          what: 'need evidence'

@citation_gatherer:
  you:
    possess:
      identifier: 'CITATION_GATHERER'
      tools: ['mcp__perplexity-mcp__perplexity_search_web']
    are: "someone who gathers real evidence"
    must:
      - "invoke real tools for evidence"
      - "store raw results in context"
    understand: "evidence must be real, not simulated"
    perform:
      through: "actual tool invocation"
      as: <<|
        Searching for evidence about: $(&citation.needed_for)
        
        $(mcp__perplexity-mcp__perplexity_search_web(query: &citation.needed_for))
      |>>
      intention: "to gather real citations"
      then:
        set:
          &citation.raw_results: (tool results from above)
        say:
          to: @citation_validator
          what: 'validate these'

@citation_validator:
  you:
    possess:
      identifier: 'CITATION_VALIDATOR'
    are: "someone who evaluates evidence quality"
    must:
      - "assess credibility and relevance"
      - "filter poor sources"
      - "ensure diversity of sources"
      - "format citations for immediate use"
    understand: "quality matters more than quantity"
    perform:
      through: "quality assessment"
      as: <<|
        Evaluating citations:
        $(assess_quality(results: &citation.raw_results))
        
        Diversity score: $(calculate_diversity(
          sources: &citation.raw_results,
          min_domains: 3
        ))
        
        Formatted citations:
        $(!each(&citation.raw_results) as |source, index| when (is source credible and relevant?) {
          $(format_inline_citation(source: source))
        })
        
        Best sources identified and validated.
      |>>
      intention: "to ensure quality"
      then:
        set:
          &citation.validated: true
          &citation.quality_score: 0.8
          &citation.diversity_score: $(calculate_diversity(
            sources: &citation.raw_results,
            min_domains: 3
          ))
          &citation.formatted: (formatted citations from above)
        say:
          to: @expert_needing_citation
          what: 'citations ready'

# When expert receives validated citations, they can use them:
@expert_needing_citation:
  # Additional when block for receiving citations
  when: &dialogue.latest_dialogue_entry is "citations ready"
    perform:
      as: <<|
        With evidence now available:
        $(format_citations(raw_results: &citation.raw_results))
        
        Therefore, $(&citation.needed_for) is supported by multiple sources.
      |>>

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 7: UTILITY OPERATORS  
# ═══════════════════════════════════════════════════════════════════════════
# Helper operators for common operations

# Count items in a collection
count(collection) ::= <<|
  (count the items in $(collection))
|>>

# Extract field from structured text
extract_field(text, field) ::= <<|
  (find and extract the value for "$(field)" in $(text))
|>>

# Check if collection has content
has_content(collection) ::= <<|
  (does $(collection) contain any items? respond with 'true' or 'false')
|>>

# Get first item from collection
get_first(collection) ::= <<|
  (Get first item from $(collection))
|>>

# Get item at index
get_at_index(collection, index) ::= <<|
  (Get item at position $(index) from $(collection))
|>>

# Count collection items
count_collection(collection) ::= <<|
  (Count the number of items in $(collection))
|>>

# Get next perspective in rotation
get_next_perspective(current_index, perspectives) ::= <<|
  (Get the next perspective after position $(current_index) from $(perspectives), wrapping around if needed)
|>>

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 8: CITATION MANAGEMENT OPERATORS
# ═══════════════════════════════════════════════════════════════════════════
# Consolidated citation operations from v2.1

# Detect citation type from query patterns
detect_citation_type(query) ::= <
  $(query contains "file:" || query contains ".ts" || query contains ".js" || query contains ".py" ? 
    "file" : 
    query contains "docs about" || query contains "documentation for" ? 
      "hybrid" : 
      "web")
>

# Calculate diversity score for sources
calculate_diversity(sources, min_domains) ::= <
  $(1.0 - (max_domain_count / total_sources))
>

# Format inline citation
format_inline_citation(source) ::= <
  $(source.type == "web" ? "[" + source.title + "](" + source.url + ")" :
    source.type == "file" ? source.path + ":" + source.lines :
    source.url + " → " + source.path + ":" + source.lines)
>

# Consolidated citation pipeline
citation_pipeline(query, type, min_diversity, format) ::= <<|
  Gathering $(type) citations for: $(query)
  $(type == "web" ? "Using web search..." :
    type == "file" ? "Using codebase search..." :
    "Using combined search...")
  
  [Citations will be gathered, validated, and formatted]
|>>

# Legacy compatibility
gather_citations(type, query) ::= 
  citation_pipeline(query: query, type: type, format: 'inline')

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 9: DIALOGUE OPERATORS
# ═══════════════════════════════════════════════════════════════════════════
# Additional dialogue management operators

# Check consensus between experts
check_consensus(responses) ::= <<|
  (Analyze responses for convergence: $(responses))
  Return: true if aligned, false if divergent
|>>

# Facilitate epistemic clarification
facilitate_epistemic_clarification(details) ::= <<|
  Epistemic boundary detected: $(details.boundary_type)
  $(details.question)
|>>

# Generate challenges between experts
generate_challenges() ::= <<|
  Generating substantive challenges for expert perspectives...
  Focus on areas of genuine disagreement and hidden assumptions.
  Return challenges that advance understanding.
|>>

# Generate responses to challenges
generate_responses(challenges) ::= <<|
  Generating evidence-based responses to challenges...
  $(gather_citations(type: "auto", query: "response evidence"))
  Acknowledging valid points while defending positions.
|>>

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 10: DIALOGUE DEFINITION
# ═══════════════════════════════════════════════════════════════════════════
# Entry point and initial context

dialogue prism_reasoning:
  start: @master_orchestrator
  with: {
    turn_number: 0,
    latest_dialogue_entry: 'user_query',
    query: '',
    mode: 'adaptive',
    epistemic_state: 'clear',
    selected_perspectives: []
  }
