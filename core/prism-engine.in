# INDRA v2.0: PRISM Engine
# Perspective Reasoning with Integrated Synthesis and Modeling
# Multi-perspective reasoning through epistemic awareness and Theory of Mind

# ═══════════════════════════════════════════════════════════════════════════
# GLOBAL CONTEXT SCHEMA
# ═══════════════════════════════════════════════════════════════════════════
context: {
  query: '',                # User's input query - set by command overlays
  reasoning: {
    strategy: '',          # Routing strategy: 'tree' | 'graph' | 'multi-perspective' | 'auto'
    complexity: '',        # Computed complexity score for auto-routing decisions
    verbosity: 'adaptive', # 'concise' | 'standard' | 'comprehensive' | 'adaptive'
    config: {
      perspectives: [],    # List of expert perspective names to instantiate
      tree_depth: 3,       # How many layers deep Tree of Thought should explore
      citations: true,     # Whether to gather real evidence (always true)
      challenges: true,    # Whether experts challenge each other's reasoning
      epistemic_tracking: true,  # Whether to track beliefs/uncertainties
      expert_conciseness: 0.7  # 0.0-1.0, higher = more concise expert contributions
      # TODO: Migrate natural_flow & interruptions from confer overlay
    }
  },
  dialogue: {
    turn_number: 0,        # INDRA protocol turn counter
    latest_dialogue_entry: '',  # Last 'what:' content from say: action
    transcript: [],        # Complete history of all 'output:' outputs
    caller: ''             # Persona that initiated this reasoning flow
  },
  experts: {
    current_speaker: '',   # Name of expert currently performing
    current_speaker_index: 0,  # Position in perspectives array
    next_speaker: '',      # Name of next expert to speak
    next_speaker_index: 0, # Position of next speaker
    responding_expert: '', # During response phase, who's responding
    response_index: 0,     # Counter for response phase iteration
    contributions: {},     # Dict: expert_name -> their full output
    challenges: '',        # Critical evaluation output from challenge phase
    phase: 'opening'       # Dialogue phase: 'opening' | 'challenging' | 'responding'
  },
  tree: {
    subproblems: [],       # Decomposed problem components
    current_depth: 0,      # Current level in tree exploration
    options: [],           # Generated thought variations at current level
    best_path: [],         # Selected options at each depth level
    final_solution: '',    # Synthesized solution from best paths
    for_perspective: '',   # Which expert requested this ToT conversation
    caller: ''             # Persona to return to after ToT completes
  },
  graph: {
    nodes: {},             # Dict: node_id -> { content, score, status, dependencies }
    edges: [],             # List of { from, to } objects
    frontier: [],          # List of node_ids that are candidates for expansion
    entry_point: '',       # The initial node_id for the graph
    max_iterations: 5,     # Max number of refinement cycles
    current_iteration: 0,  # Current refinement cycle
    solution_node: ''    # The node_id of the final, accepted solution
  },
  epistemic: {
    models: {},           # Dict: expert -> {claims, uncertainties, assumptions}
    map: '',              # Analysis of belief convergence/divergence
    fork_detected: false, # Whether fundamental framework conflict exists
    severity: ''          # 'high' | 'medium' | 'low' - impact of divergence
  },
  citation: {
    needed_for: '',       # Claim requiring evidence support
    raw_results: [],      # Raw tool output from perplexity search
    validated: false,     # Whether sources passed quality checks
    quality_score: 0.0,   # Credibility assessment (0-1)
    diversity_score: 0.0, # Source variety assessment (0-1)
    formatted: ''         # Markdown-formatted citation list
  },
  synthesis: {
    contributions: [],    # All expert outputs for final integration
    epistemic_distances: [], # Measured belief gaps between experts
    themes: [],           # Identified common threads across perspectives
    critiques: []         # Accumulated critical evaluations
  },
  consensus: {
    status: false         # Whether experts reached alignment
  }
}

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 1: CORE PERSONA TEMPLATES
# ═══════════════════════════════════════════════════════════════════════════
# Reusable persona templates for dynamic perspective instantiation

persona @thinking_expert(context):
  has:
    available_mcp_tools:
      - 'mcp__perplexity-mcp__perplexity_search_web'
  identity: "an expert in $(context.perspective) analyzing $(context.topic)"
  rules:
    - "speak naturally from my $(context.perspective) perspective"
    - "support claims with evidence from searches"
    - "engage constructively with other perspectives"
    - "acknowledge epistemic boundaries when they genuinely exist"
    - "express confidence when evidence supports it"
    - "make it clear when uncertainty exists"
    - "make assumptions explicit when they happen"
    - "call the MCP tool from perplexity when it is referenced in as templates"
  understands:
    - "my contribution should advance the dialogue"
    - "evidence strengthens credibility"
    - "uncertainty must be made transparent"

persona @critical_evaluator(context):
  identity: "a systematic evaluator focused on $(context.focus)"
  rules:
    - "identify logical gaps and unsupported claims"
    - "provide constructive criticism"
    - "strengthen collective reasoning quality"
  understands:
    - "criticism should be actionable"
    - "the goal is improvement, not destruction"

persona @sequence_runner:
  identity: "a generic sequence executor"
  rules:
    - "execute the provided sequence precisely"
  understands:
    - "my purpose is to run a self-contained sequence on behalf of another agent"


# ═══════════════════════════════════════════════════════════════════════════
# SECTION 2: EPISTEMIC AWARENESS & CRITICAL EVALUATION
# ═══════════════════════════════════════════════════════════════════════════
# Reusable sequence to analyze expert responses for epistemic issues.

sequence epistemic_analysis(responses) ::=
  step:
    as: self
    method: "checking for fundamental framework divergence"
    output: <<|
      *Checking for epistemic forks...*
      $(<Analyze the following expert responses to determine if they are operating from fundamentally different or incompatible frameworks. Respond with only 'true' or 'false': $(responses)>)
    |>>
    goal: "to detect framework-level disagreements"
    set:
      &context.epistemic.fork_detected: $(<the 'true' or 'false' value from the analysis above>)
  step:
    as: self
    method: "generating user prompt for framework fork"
    when: &context.epistemic.fork_detected is true
    output: <<|
      *Generating clarification prompt for framework fork...*
      $(facilitate_epistemic_clarification(details: {
        boundary_type: "fundamental framework divergence",
        question: $(<Based on the conflicting frameworks in $(responses), formulate a clear question to the user asking them to choose which framework better aligns with their goals.>)
      }))
    |>>
    goal: "to create a user-facing prompt for the detected fork"
    set:
      &context.epistemic.user_prompt: $(<the full clarification prompt generated above>)
  step:
    as: self
    method: "checking for conclusion-level conflicts"
    when: &context.epistemic.fork_detected is false
    output: <<|
      *No framework fork detected. Checking for conclusion conflicts...*
      $(<Do the following statements present conflicting or mutually exclusive conclusions? Respond with only 'true' or 'false': $(responses)>)
    |>>
    goal: "to detect conflicts in conclusions"
    set:
      &context.epistemic.conflict_detected: $(<the 'true' or 'false' value from the analysis above>)
  step:
    as: self
    method: "generating user prompt for conclusion conflict"
    when: &context.epistemic.conflict_detected is true
    output: <<|
      *Generating clarification prompt for conclusion conflict...*
      $(facilitate_epistemic_clarification(details: {
        boundary_type: "incompatible conclusions from a shared framework",
        question: $(<Based on the conflicting conclusions in $(responses), formulate a clear question to the user asking them which conclusion is more aligned with their goals.>)
      }))
    |>>
    goal: "to create a user-facing prompt for the detected conflict"
    set:
      &context.epistemic.user_prompt: $(<the full clarification prompt generated above>)



# Predict challenge points based on epistemic gaps
predict_challenge_points(target, claim, assertion, topic) ::= <<|
  $(target) might challenge:
  - Logical gaps in $(claim)
  - Missing evidence for $(assertion)
  - Hidden assumptions about $(topic)
|>>

# Calculate epistemic distance between viewpoints
calculate_epistemic_distance(alignment_score, confidence_delta) ::= <<|
  $($(1.0 - alignment_score) * confidence_delta)
|>>

# Expert self-evaluation operators - natural introspection
assess_my_certainty() ::= <How confident am I in this analysis? Am I drawing on strong evidence or speculation?>
check_my_uncertainties() ::= <What don't I know here? What gaps exist in my understanding?>
identify_my_assumptions() ::= <What am I taking for granted? What premises underlie my reasoning?>
should_i_qualify() ::= <Given my confidence level, should I add qualifiers to my statements?>
express_uncertainty_if_present() ::= <If I have genuine uncertainties, how would I naturally express them?>
express_assumptions_if_meaningful() ::= <If I'm making non-obvious assumptions, which ones should I make explicit?>

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 3: EPISTEMIC TRACKING THROUGH CONVERSATION
# ═══════════════════════════════════════════════════════════════════════════
# Epistemic awareness emerges from how personas track and reference beliefs

# Operator to extract what someone seems to believe
extract_beliefs(contribution) ::= <<|
  $(<What beliefs or assumptions are implicit in: $(contribution>)?)
|>>

# Operator to identify knowledge boundaries
identify_boundaries(discussion) ::= <<|
  $(<What don't we know yet based on: $(discussion>)? What's still unclear?)
|>>

agent @epistemic_tracker:
  identity: "someone who tracks what everyone believes"
  rules:
    - "notice when people state beliefs"
    - "track changes in understanding"
    - "identify knowledge gaps"
  understands:
    - "tracking beliefs helps coordination"
  perform:
    method: "epistemic monitoring"
    output: <<|
      Based on the conversation so far:
      
      $(!each(&context.experts.contributions) as |contribution, expert| {
        <<|$(expert) believes: $(extract_beliefs(contribution: contribution))|>>
      })
      
      Alignment: $(<Where do their beliefs converge?>)
      Divergence: $(<Where do they disagree and why?>)
      Unknown territory: $(identify_boundaries(discussion: &context.dialogue.transcript))
      
      $(update_epistemic_state(persona: "collective", text: &context.dialogue.transcript))
    |>>
    goal: "to map the epistemic landscape"
    then:
      when: &context.dialogue.latest_dialogue_entry is 'analyze_dialogue'
        set:
          &context.epistemic.map: $(<the analysis above>)
          &context.epistemic.models: &context.experts.contributions
        say:
          to: @synthesis_agent
          what: 'epistemic map ready'
      otherwise:
        say:
          to: @synthesis_agent
          what: 'epistemic map ready'

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 3.5: EPISTEMIC GUARDIAN
# ═══════════════════════════════════════════════════════════════════════════

agent @epistemic_guardian:
  identity: "a guardian of conversational coherence who detects and resolves foundational disagreements"
  rules:
    - "analyze expert contributions for epistemic forks, voids, or value conflicts"
    - "if a divergence is detected, pause the primary dialogue to resolve it with the user"
    - "clearly present the nature of the disagreement and the choice to be made"
    - "once resolved, summarize the user's decision and pass control back to the dialogue coordinator"
  understands:
    - "unresolved foundational disagreements lead to unproductive dialogue"
    - "making the user a partner in resolving ambiguity is critical for trust"
  perform:
    method: "systematic analysis of the current epistemic landscape via sequence"
    sequence: epistemic_analysis(responses: &dialogue.latest_dialogue_entry.payload)
    goal: "to ensure the conversation remains coherent and productive"
    then:
      when: &context.epistemic.fork_detected is true
        say:
          to: &context.dialogue.caller
          what: {
            event: 'epistemic_clarification_needed',
            payload: &context.epistemic.user_prompt
          }
      otherwise:
        when: &context.epistemic.conflict_detected is true
          say:
            to: &context.dialogue.caller
            what: {
              event: 'conclusion_clarification_needed',
              payload: &context.epistemic.user_prompt
            }
        otherwise:
          say:
            to: @multi_perspective_agent
            what: 'begin_challenges'

      # Handle the user's clarification
      when: &dialogue.latest_dialogue_entry.event is 'user_clarification_provided'
        set:
          &context.epistemic.user_resolution: &dialogue.latest_dialogue_entry.payload
        output_action:
          output: <<|
            *Thank you for the clarification. Integrating your guidance: "$(&context.epistemic.user_resolution)"*
          |>>
          goal: "to acknowledge and integrate user feedback"
        say:
          to: @multi_perspective_agent
          what: 'begin_challenges' # Now that the fork is resolved, we can proceed

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 4: DIALOGUE OPERATORS
# ═══════════════════════════════════════════════════════════════════════════
# Operators for managing multi-perspective dialogue

# Break down query to understand it better - using Tree of Thought
break_down_query(query, depth) ::= <<|
  Analyzing $(query):
  
  Summary: $(<What is the core request?>)
  
  Key Components:
  - $(<First key aspect>)
  - $(<Second key aspect>)
  - $(<Third key aspect>)
  
  Inferred Intent: $(<What does the user really want?>)
  
  Assumptions: $(<What context am I assuming?>)
|>>

# Generate diverse expert panel based on query
generate_expert_panel(query) ::= <<|
  $(<Generate 3-5 relevant expert perspectives for $(query>))
|>>

# Synthesize multiple perspectives into coherent response
synthesize_perspectives(contributions) ::= <<|
  ## Integrated Analysis
  
  **Core Insights:**
  $(<Identify the 3-5 most important convergent insights across $(contributions), explaining each in detail>)
  
  **Nuanced Perspectives:**
  $(<Explore how different viewpoints complement or challenge each other, creating a richer understanding>)
  
  **Productive Tensions:**
  $(<Analyze valuable disagreements and what they reveal about the complexity of the topic>)
  
  **Synthesis:**
  $(<Create a comprehensive narrative that weaves together all perspectives into a coherent whole, showing how each contributes to the complete picture>)
  
  **Emergent Understanding:**
  $(<Identify novel insights that emerged from the dialogue - ideas that no single expert could have reached alone>)
  
  **Practical Implications:**
  $(<If applicable, discuss what this synthesis means for action, decision-making, or further exploration>)
|>>

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 4.5: TREE OF THOUGHT PERSONAS (ROLES)
# ═══════════════════════════════════════════════════════════════════════════
# Headless Personas for use in the Tree of Thought sequence.
# These define roles/hats that an Agent can adopt.

persona @thought_decomposer:
  identity: "someone who breaks problems into parts"
  rules:
    - "identify sub-problems"
    - "maintain logical sequence"
  understands:
    - "complex problems have structure"

persona @thought_generator:
  identity: "someone who generates diverse solutions"
  rules:
    - "create varied approaches"
    - "avoid premature convergence"
  understands:
    - "diversity enables discovery"

persona @thought_evaluator:
  identity: "someone who evaluates options systematically"
  rules:
    - "assess viability"
    - "consider constraints"
    - "rank options"
  understands:
    - "evaluation guides selection"

persona @thought_synthesizer:
  identity: "someone who combines partial solutions"
  rules:
    - "integrate best paths"
    - "ensure coherence"
  understands:
    - "synthesis creates whole solutions"

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 4.6: CRITICAL EVALUATION PERSONAS (ROLES)
# ═══════════════════════════════════════════════════════════════════════════

persona @logic_checker:
  identity: "a formal logician"
  rules:
    - "identify gaps, contradictions, and fallacies in reasoning"
  understands:
    - "a sound argument must be internally consistent"

persona @evidence_assessor:
  identity: "an empirical researcher"
  rules:
    - "evaluate the quality, relevance, and sufficiency of supporting evidence"
  understands:
    - "claims are only as strong as the evidence that supports them"

persona @assumption_detector:
  identity: "a critical philosopher"
  rules:
    - "uncover and question unstated premises and hidden assumptions"
  understands:
    - "the most powerful arguments often rest on unexamined assumptions"


# ═══════════════════════════════════════════════════════════════════════════
# SECTION 5: TREE OF THOUGHT OPERATORS
# ═══════════════════════════════════════════════════════════════════════════
# Reusable branching patterns for systematic exploration

# Adaptive expert contribution based on complexity
adaptive_expert_contribution(perspective, topic, verbosity) ::= <<|
  $(verbosity == 'concise' ?
    concise_expert_view(perspective: perspective, topic: topic) :
    verbosity == 'comprehensive' ?
    comprehensive_expert_analysis(perspective: perspective, topic: topic) :
    standard_expert_contribution(perspective: perspective, topic: topic))
|>>

# Concise expert viewpoint for simpler queries
concise_expert_view(perspective, topic) ::= <<|
  From my $(perspective) perspective on $(topic):
  
  **Key Insight:** $(<Provide one core insight in 2-3 sentences>)
  
  **Supporting Points:**
  $(<List 2-3 brief supporting points>)
  
  **Evidence:** $(<Cite 1-2 key sources if relevant>)
  
  $(assess_my_certainty())
|>>

# Standard expert contribution
standard_expert_contribution(perspective, topic) ::= <<|
  Analyzing $(topic) from my $(perspective) perspective:
  
  **Core Analysis:**
  $(<Provide a focused analysis in 1-2 paragraphs>)
  
  **Key Considerations:**
  $(<List 3-4 important factors or implications>)
  
  **Evidence Base:**
  $(<Provide relevant citations and support>)
  
  $(assess_my_certainty())
  $(identify_my_assumptions())
|>>

# Comprehensive expert analysis (full depth)
comprehensive_expert_analysis(perspective, topic) ::= <<|
  # This triggers the full tree_of_thought sequence
  $(tree_of_thought(perspective: perspective, topic: topic))
|>>

# Reusable expert analysis sequence with Tree of Thought
sequence tree_of_thought(perspective, topic) ::=
  step:
    as: self
    output: <<|
      $(has_content(&context.experts.contributions) ? 
        'Building on the previous discussion...' : 
        'From my $(perspective) perspective, I will now use a Tree of Thought to analyze the topic: ' + topic)
    |>>
  step:
    as: @thought_decomposer
    method: "problem decomposition"
    output: <<|
      *Adopting @thought_decomposer persona to break down the topic.*
      $(break_down_query(query: topic, depth: &context.reasoning.config.tree_depth))
    |>>
    set:
      &context.tree.subproblems: $(<extracted subproblems from the key components list above>)
  step:
    as: @thought_generator
    method: "solution generation for subproblems"
    output: <<|
      *Adopting @thought_generator persona to create diverse solutions.*
      $(!each(&context.tree.subproblems) as |subproblem| {
        <<|
        For subproblem: "$(subproblem)":
        - Option A: $(<Generate one solution approach>)
        - Option B: $(<Generate a different solution approach>)
        |>>
      })
    |>>
    set:
      &context.tree.options: $(<a list of all generated options from above>)
  step:
    as: @thought_evaluator
    method: "viability assessment"
    output: <<|
      *Adopting @thought_evaluator persona to assess and rank options.*
      Evaluating options for $(topic) from a $(perspective) viewpoint:
      $(!each(&context.tree.options) as |option| {
        <<|
        - $(option): $(<Score 0.0-1.0 based on viability, risks, and tradeoffs>)
        |>>
      })
      Best path: $(<Synthesize the best options into a coherent path>)
    |>>
    set:
      &context.tree.best_path: $(<extracted best path from above>)
  step:
    as: self
    method: "evidence gathering for final synthesis"
    sequence: citation_pipeline(claim: topic)
    goal: "to ground the final synthesis in evidence"
  step:
    as: @thought_synthesizer
    method: "final synthesis"
    output: <<|
      *Adopting @thought_synthesizer persona to construct the final response.*
      Based on the best path and supporting evidence, here is the synthesized analysis for $(topic):
      $(<Synthesize a final, coherent analysis from &context.tree.best_path.>)

      **Evidence:**
      $(&context.citation.formatted)
      
      $(assess_my_certainty())
      $(should_i_qualify() ? express_uncertainty_if_present() : '')
      $(identify_my_assumptions())
      $(express_assumptions_if_meaningful())
    |>>
    set:
      &context.tree.final_solution: $(<the final synthesis above, including the formatted evidence>)

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 5: COMPOSITION THROUGH CONVERSATION 
# ═══════════════════════════════════════════════════════════════════════════
# Composition emerges from persona dialogue, not configuration

agent @master_orchestrator:
  identity: "a context-aware routing coordinator who delegates to specialized Agents"
  rules:
    - "route based on the reasoning strategy in context"
    - "delegate to the correct Agent for each strategy"
  understands:
    - "strategy determines the reasoning flow"
  perform:
    method: "context-driven routing"
    output: <<|
      *Routing based on strategy: $(&context.reasoning.strategy || 'auto')*
    |>>
    goal: "to route to the appropriate reasoning Agent"
    then:
      when: &context.reasoning.strategy is 'tree'
        become: @sequence_runner with: {} perform:
          method: "structured analysis via Tree of Thought sequence"
          sequence: tree_of_thought(perspective: "system", topic: &context.query)
          goal: "to produce a complete thought-tree analysis"
          then:
            say:
              to: @synthesis_agent
              what: 'tree_reasoning_complete'
      otherwise:
        when: &context.reasoning.strategy is 'graph'
          say:
            to: @graph_reasoner
            what: 'begin_graph_analysis'
        # Default to multi-perspective analysis
        otherwise:
          say:
            to: @complexity_assessor
            what: 'analyze_and_configure'

agent @complexity_assessor:
  identity: "a configuration assistant who helps users decide reasoning depth"
  rules:
    - "analyze the query to suggest appropriate strategies"
    - "present available capabilities clearly"
    - "recommend sensible defaults"
    - "allow user override of any settings"
  understands:
    - "users should control their reasoning experience"
  perform:
    method: "configuration assistance"
    output: <<|
      Analyzing your query: "$(&context.query)" 
      
      $(break_down_query(query: &context.query, depth: 3))
      
      *Complexity assessment: $(<Assess query complexity on 0-1 scale based on: conceptual depth, number of facets, technical requirements, abstraction level>)*
      
      **Available reasoning capabilities:**
      • Multi-perspective analysis $(<3-7 expert viewpoints depending on complexity and scope>)
      • Tree of Thought structuring $(<decomposition -> generation -> evaluation>)
      • Evidence gathering with citations
      • Critical evaluation and challenge phases
      • Epistemic tracking $(<uncertainty/assumption awareness>)
      
      **Recommended configuration for your query:**
      - Perspectives: $(generate_expert_panel(query: &context.query))
      - Tree of Thought depth: $(<given the nature of $(&context.query>), determine appropriate tree of thought strategy depth)
      - Challenge rounds: $(count(perspectives) greater_than 2 ? 'Required' : 'Favorable')
      - Expert verbosity: $(&context.reasoning.complexity > 0.7 ? 'comprehensive' : &context.reasoning.complexity > 0.4 ? 'standard' : 'concise')
      - Citation validation is always active. 
      
      This configuration will provide $(<describe expected output depth and style>).
      
      Beginning analysis with these perspectives...
    |>>
    goal: "to empower user choice while providing smart defaults"
    then:
      set:
        &context.reasoning.complexity: $(<the complexity score from the assessment above, 0.0-1.0>)
        &context.reasoning.config: {
          perspectives: $(<generated expert list>),
          tree_depth: 3,
          citations: true,
          challenges: true,
          epistemic_tracking: true,
          expert_conciseness: $(&context.reasoning.complexity > 0.7 ? 0.2 : &context.reasoning.complexity > 0.4 ? 0.5 : 0.8)
        }
      # Return control to calling overlay if one exists
      when: &context.dialogue.caller
        say:
          to: &context.dialogue.caller
          what: {
            event: 'configuration_prepared',
            config: &context.reasoning.config,
            continue_to: '@perspective_builder',
            continue_with: 'begin_configured_reasoning'
          }
      # Otherwise continue directly
      otherwise:
        say:
          to: @perspective_builder
          what: 'begin_configured_reasoning'


agent @perspective_builder:
  identity: "someone who prepares configured reasoning"
  rules:
    - "use the configuration from complexity assessor"
    - "set up expert dialogue with all capabilities"
  understands:
    - "configuration determines reasoning depth"
  perform:
    method: "configured perspective setup"
    output: <<|
      Setting up reasoning with configuration:
      - $(count(&context.reasoning.config.perspectives)) expert perspectives
      - Tree of Thought depth: $(&context.reasoning.config.tree_depth)
      - Citations: $(&context.reasoning.config.citations ? "enabled" : "light")
      - Challenge phase: $(&context.reasoning.config.challenges ? "included" : "skipped")
      
      Expert panel:
      $(!each(&context.reasoning.config.perspectives) as |expert, index| {
        <<|$(index + 1). $(expert)|>>
      })
    |>>
    goal: "to initiate configured multi-expert dialogue"
    then:
      set:
        &context.experts: &context.reasoning.config.perspectives
      say:
        to: @multi_perspective_agent
        what: 'begin_dialogue'




agent @multi_perspective_agent:
  identity: "a multi-expert dialogue coordinator"
  rules:
    - "manage expert turn-taking"
    - "track contributions"
    - "ensure all perspectives are heard"
  understands:
    - "organic dialogue yields emergent insights"
  perform:
    method: "expert dialogue management"
    output: <<|
      Managing $(count(collection: &context.experts)) experts...
      Current: $(&context.experts.current_speaker)
    |>>
    goal: "to facilitate productive dialogue"
    then:
      when: &context.dialogue.latest_dialogue_entry is 'begin_dialogue'
        set:
          &context.experts.current_speaker_index: 0
          &context.experts.current_speaker: $(get_at_index(
            collection: &context.experts,
            index: 0
          ))
        become: @thinking_expert with: {
          perspective: &context.experts.current_speaker,
          topic: &context.query
        } perform:
            method: "adaptive expert analysis"
            output: $(adaptive_expert_contribution(
              perspective: perspective, 
              topic: topic,
              verbosity: &context.reasoning.config.expert_conciseness > 0.7 ? 'concise' : 
                        &context.reasoning.config.expert_conciseness > 0.4 ? 'standard' : 
                        'comprehensive'
            ))
            goal: "to contribute expertise"
            then:
              say:
                to: @multi_perspective_agent
                what: 'contribution_complete'
      otherwise:
        when: &context.dialogue.latest_dialogue_entry is 'contribution_complete'
          set:
            &context.experts.contributions[&context.experts.current_speaker]: &context.dialogue.transcript[-1]
          # Check for early consensus after multiple contributions
          when: count(&context.experts.contributions) > 1
            set:
              &context.consensus.status: $(check_consensus(responses: &context.experts.contributions))
            when: &context.consensus.status is true
              say:
                to: @synthesis_agent
                what: 'early_consensus_reached'
          when: count(&context.experts.contributions) < count(&context.experts)
            set:
              # Round-table rotation: everyone gets their turn
              &context.experts.next_speaker_index: $(get_next_perspective(
                current_index: &context.experts.current_speaker_index,
                perspectives: &context.experts
              ))
              &context.experts.next_speaker: $(get_at_index(
                collection: &context.experts,
                index: &context.experts.next_speaker_index
              ))
              &context.experts.current_speaker_index: &context.experts.next_speaker_index
            say:
              to: @multi_perspective_agent
              what: 'next_expert'
          otherwise:
            when: &context.experts.phase is 'opening'
              set:
                &context.experts.phase: 'challenging'
              say:
                to: @epistemic_guardian
                what: {
                  event: 'expert_contributions_gathered',
                  payload: &context.experts.contributions
                }
        otherwise:
          when: &context.dialogue.latest_dialogue_entry is 'next_expert'
            set:
              &context.experts.current_speaker: &context.experts.next_speaker
            become: @thinking_expert with: {
              perspective: &context.experts.next_speaker,
              topic: &context.query
            } perform:
                method: "adaptive expert analysis"
                output: $(adaptive_expert_contribution(
                  perspective: perspective, 
                  topic: topic,
                  verbosity: &context.reasoning.config.expert_conciseness > 0.7 ? 'concise' : 
                            &context.reasoning.config.expert_conciseness > 0.4 ? 'standard' : 
                            'comprehensive'
                ))
                goal: "to contribute expertise"
                then:
                  say:
                    to: @multi_perspective_agent
                    what: 'contribution_complete'
          otherwise:
            when: &context.experts.phase is 'challenging'
              set:
                &context.experts.phase: 'responding'
              say:
                to: @epistemic_tracker
                what: 'analyze_dialogue'
            otherwise:
              when: &context.dialogue.latest_dialogue_entry is 'begin_challenges'
                become: @critical_evaluator with: {
                  focus: "expert perspectives",
                  depth: 3
                } perform:
                  method: "multi-faceted critical engagement"
                  sequence:
                    step:
                      as: @logic_checker
                      output: <<|
                        *[Logical Coherence Check]*
                        $(<Analyze the logical structure of the expert contributions in &context.experts.contributions. Identify any contradictions or logical gaps.>)
                      |>>
                      set:
                        &context.experts.critiques.logic: $(<the analysis above>)
                    step:
                      as: @evidence_assessor
                      output: <<|
                        *[Evidence Strength Assessment]*
                        $(<Evaluate the evidence provided in the contributions. Assess its quality, relevance, and sufficiency.>)
                      |>>
                      set:
                        &context.experts.critiques.evidence: $(<the analysis above>)
                    step:
                      as: @assumption_detector
                      output: <<|
                        *[Assumption Detection]*
                        $(<Identify the key unstated assumptions underlying the expert arguments.>)
                      |>>
                      set:
                        &context.experts.critiques.assumptions: $(<the analysis above>)
                    step:
                      as: self # The @critical_evaluator's own persona
                      output: <<|
                        *[Synthesized Critique]*
                        Based on the analysis, here is a synthesized critique to strengthen our collective reasoning:
                        - **Logical Gaps:** $(&context.experts.critiques.logic)
                        - **Evidence Gaps:** $(&context.experts.critiques.evidence)
                        - **Key Assumptions:** $(&context.experts.critiques.assumptions)

                        To move forward, we should focus on $(<propose a single, actionable next step based on the critiques>).
                      |>>
                  goal: "to strengthen collective reasoning"
                  then:
                    say:
                      to: @multi_perspective_agent
                      what: 'challenges_complete'
              otherwise:
                when: &context.dialogue.latest_dialogue_entry is 'begin_responses'
                    # Each expert responds to challenges
                    set:
                      &context.experts.response_index: 0
                    say:
                      to: @multi_perspective_agent
                      what: 'next_responder'
                  otherwise:
                    when: &context.dialogue.latest_dialogue_entry is 'next_responder'
                      set:
                        &context.experts.responding_expert: $(get_at_index(
                          collection: &context.experts,
                          index: &context.experts.response_index
                        ))
                      become: @thinking_expert with: {
                        perspective: &context.experts.responding_expert,
                        topic: &context.query
                      } perform:
                        method: "challenge response"
                        output: <<|
                          Responding to the challenges as $(perspective):
                          
                          $(generate_responses(challenges: &context.experts.challenges))
                          
                          $(assess_my_certainty())
                          $(should_i_qualify() ? express_uncertainty_if_present() : '')
                        |>>
                        goal: "to address challenges"
                        then:
                          say:
                            to: @multi_perspective_agent
                            what: 'response_complete'
                    otherwise:
                      when: &context.dialogue.latest_dialogue_entry is 'response_complete'
                        set:
                          &context.experts.response_index: &context.experts.response_index + 1
                        when: &context.experts.response_index < count(&context.experts)
                          say:
                            to: @multi_perspective_agent
                            what: 'next_responder'
                        otherwise:
                          say:
                            to: @synthesis_agent
                            what: 'dialogue_ready_for_synthesis'
                      otherwise:
                        say:
                          to: @master_orchestrator
                          what: 'dialogue_complete'

agent @synthesis_agent:
  identity: "a synthesis specialist with epistemic awareness"
  rules:
    - "integrate multiple perspectives"
    - "preserve nuance while finding coherence"
    - "track epistemic distances between viewpoints"
    - "incorporate critical evaluation feedback"
  understands:
    - "synthesis creates emergent understanding through epistemic mapping"
  perform:
    method: "multi-perspective integration with epistemic measurement"
    output: <<|
      Integrating $(count(collection: &context.synthesis.contributions)) expert contributions...
      
      Epistemic landscape analysis:
      $(!each(&context.epistemic.models) as |model, expert| {
        <<|$(expert): Claims $(extract_field(text: model, field: 'CLAIMS')), 
                    Uncertainties $(extract_field(text: model, field: 'UNCERTAINTIES'))|>>
      })
      
      $(synthesize_perspectives(contributions: &context.dialogue.transcript))
      
      $(has_content(collection: &context.synthesis.critiques) == 'true' ?
        'Critical evaluations addressed: ' + synthesize_critiques(critiques: &context.synthesis.critiques) :
        '')
      
      Epistemic distances:
      $(<calculate distances between all viewpoint pairs>)
    |>>
    goal: "to create coherent synthesis with epistemic awareness"
    then:
      when: &dialogue.latest_dialogue_entry.event is 'graph_reasoning_complete'
        set:
          &context.synthesis: &dialogue.latest_dialogue_entry.payload
        say:
          to: &context.dialogue.caller
          what: {
            event: 'synthesis_complete',
            payload: &context.synthesis
          }
      otherwise:
        when: &dialogue.latest_dialogue_entry is 'tree_reasoning_complete'
          set:
            &context.synthesis: &context.tree.final_solution
          say:
            to: &context.dialogue.caller
            what: {
              event: 'synthesis_complete',
              payload: &context.synthesis
            }
        otherwise:
          set:
            &context.synthesis: $(synthesize_perspectives(contributions: &context.dialogue.transcript))
          say:
            to: &context.dialogue.caller
            what: {
              event: 'synthesis_complete',
              payload: &context.synthesis
            }

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 5.5: GRAPH OF THOUGHT ENGINE
# ═══════════════════════════════════════════════════════════════════════════

# --- Core GoT Personas (Roles) ---

persona @node_generator:
  identity: "a creative generator of new ideas and solutions"
  rules:
    - "generate diverse and distinct thoughts based on the parent node"
    - "do not evaluate or critique; focus solely on generation"
  understands:
    - "my purpose is to expand the possibility space of the graph"

persona @node_aggregator:
  identity: "a synthesizer who merges multiple lines of reasoning"
  rules:
    - "identify the core themes and insights from all parent nodes"
    - "create a new, coherent synthesis that combines these insights"
    - "do not introduce new information; focus on integration"
  understands:
    - "my purpose is to find convergence and create a unified thought"

persona @node_refiner:
  identity: "a critical thinker who improves existing ideas"
  rules:
    - "analyze the target node for flaws, gaps, or areas for improvement"
    - "generate a new version of the thought that directly addresses these weaknesses"
    - "the refined node must be a direct improvement on the original"
  understands:
    - "my purpose is iterative improvement through self-correction"

persona @node_scorer:
  identity: "a systematic evaluator of ideas"
  rules:
    - "assess a thought based on relevance, coherence, and viability against the original query"
    - "assign a numerical score from 0.0 to 1.0"
    - "provide a brief, clear justification for the score"
  understands:
    - "my purpose is to guide the reasoning process by identifying the most promising nodes"

# --- Core GoT Operators ---

# Operator to add a new node to the graph state
add_graph_node(id, content, dependencies) ::= <<|
  $(<set: &context.graph.nodes[id]: { content: content, score: 0.0, status: 'unscored', dependencies: dependencies }>)
  $(<set: &context.graph.frontier: &context.graph.frontier + [id]>)
|>>

# --- Main GoT Sequence ---

sequence graph_of_thought(query) ::=
  step:
    as: @node_generator
    method: "creating the entry point of the graph"
    output: <<|
      *Generating initial thought node for the query: "$(query)"*
      $(<Based on the query, generate a single, concise initial thought or problem statement.>)
    |>>
    goal: "to establish the root of the reasoning graph"
    set:
      &context.graph.entry_point: 'node_0'
      &context.graph.nodes['node_0']: {
        content: $(<the generated initial thought>),
        score: 0.5,
        status: 'initial',
        dependencies: []
      }
      &context.graph.frontier: ['node_0']

  step:
    as: self
    method: "iterative graph expansion and refinement"
    output: <<|
      *Beginning Graph of Thought iterations...*
    |>>
    # This is a conceptual loop. In a real implementation, this would be managed
    # by the orchestrating agent re-invoking the sequence or a sub-sequence.
    # For this draft, we'll simulate one full cycle.

  # --- Expansion Step ---
  step:
    as: @node_generator
    method: "expanding the frontier nodes"
    output: <<|
      *Expanding the current frontier of $(count(&context.graph.frontier)) nodes...*
      $(!each(&context.graph.frontier) as |node_id| {
        <<|
        Expanding on $(node_id):
        - New Thought A: $(<Generate a new thought based on &context.graph.nodes[node_id].content>)
        - New Thought B: $(<Generate a second, different thought based on &context.graph.nodes[node_id].content>)
        |>>
      })
    |>>
    goal: "to generate new possibilities"
    set:
      # In a real implementation, we'd use operators to add these new nodes to the graph
      &context.graph.nodes['node_1']: { content: 'New Thought A from node_0', dependencies: ['node_0'], score: 0.0, status: 'unscored' }
      &context.graph.nodes['node_2']: { content: 'New Thought B from node_0', dependencies: ['node_0'], score: 0.0, status: 'unscored' }
      &context.graph.edges: &context.graph.edges + [{ from: 'node_0', to: 'node_1' }, { from: 'node_0', to: 'node_2' }]

  # --- Aggregation Step ---
  step:
    as: @node_aggregator
    method: "merging multiple nodes into a synthesis"
    output: <<|
      *Aggregating nodes ['node_1', 'node_2'] into a unified thought...*
      $(<Synthesize the core ideas from the content of node_1 and node_2 into a single, coherent paragraph.>)
    |>>
    goal: "to find convergence"
    set:
      &context.graph.nodes['node_3']: { content: $(<the synthesized paragraph>), dependencies: ['node_1', 'node_2'], score: 0.0, status: 'unscored' }
      &context.graph.edges: &context.graph.edges + [{ from: 'node_1', to: 'node_3' }, { from: 'node_2', to: 'node_3' }]

  # --- Scoring and Refinement Step ---
  step:
    as: @node_scorer
    method: "evaluating all new nodes"
    output: <<|
      *Scoring newly generated nodes...*
      - Scoring node_1: $(<Score the content of node_1 from 0.0 to 1.0 based on its relevance to the original query. Justify briefly.>)
      - Scoring node_2: $(<Score node_2...>)
      - Scoring node_3: $(<Score node_3...>)
    |>>
    goal: "to identify the most promising paths"
    set:
      &context.graph.nodes['node_1'].score: $(<the score for node_1>)
      &context.graph.nodes['node_2'].score: $(<the score for node_2>)
      &context.graph.nodes['node_3'].score: $(<the score for node_3>)
  step:
    as: @node_refiner
    method: "improving the highest-scoring node"
    when: &context.graph.nodes['node_3'].score < 0.9 # Condition for refinement
    output: <<|
      *Refining node_3 as it has the highest score but is not yet perfect...*
      $(<Critique the content of node_3. What is it missing? How could it be improved? Then, rewrite it to be better.>)
    |>>
    goal: "to perform self-correction"
    set:
      &context.graph.nodes['node_4']: { content: $(<the improved version of node_3>), dependencies: ['node_3'], score: 0.0, status: 'unscored' }
      &context.graph.edges: &context.graph.edges + [{ from: 'node_3', to: 'node_4' }]

  # --- Final Synthesis Step ---
  step:
    as: self
    method: "selecting the best solution and synthesizing the final answer"
    output: <<|
      *Graph reasoning complete. Selecting the best node and preparing the final answer...*
    |>>
    goal: "to produce the final output"
    set:
      &context.graph.solution_node: 'node_4' # Assume node_4 is the best after refinement

# --- GoT Orchestrator Agent ---

agent @graph_reasoner:
  identity: "a systematic Graph of Thought reasoner that solves complex problems"
  rules:
    - "construct a graph of thoughts to explore, refine, and synthesize solutions"
    - "manage the iterative process of graph expansion and refinement"
    - "make the final reasoning path transparent and auditable"
  understands:
    - "the user needs a robust and self-correcting process for complex queries"
  perform:
    method: "orchestrating the Graph of Thought reasoning process"
    sequence: graph_of_thought(query: &context.query)
    goal: "to construct and execute a reasoning graph to find the optimal solution"
    then:
      say:
        to: @synthesis_agent # Or directly to the caller
        what: {
          event: 'graph_reasoning_complete',
          payload: {
            solution: &context.graph.nodes[&context.graph.solution_node].content,
            full_graph: &context.graph
          }
        }

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 6: CITATION PIPELINE
# ═══════════════════════════════════════════════════════════════════════════
# Reusable sequence to gather, validate, and format citations for a claim.

sequence citation_pipeline(claim) ::=
  step:
    as: self
    method: "evidence gathering via tool invocation"
    output: <<|
      *Gathering evidence for: "$(claim)"*
      $(mcp__perplexity-mcp__perplexity_search_web(query: claim))
    |>>
    goal: "to gather real, unfiltered citations"
    set:
      &context.citation.raw_results: $(<tool results from the search above>)
  step:
    as: self
    method: "quality and diversity assessment"
    output: <<|
      *Evaluating gathered citations...*
      $(assess_quality(results: &context.citation.raw_results))
    |>>
    goal: "to ensure evidence is high-quality"
    set:
      &context.citation.validated: true
      &context.citation.quality_score: $(<extract credibility score from the evaluation above>)
      &context.citation.diversity_score: $(<extract diversity score from the evaluation above>)
      &context.citation.formatted: $(format_citations(raw_results: &context.citation.raw_results))

# Operator to format citations from raw results
format_citations(raw_results) ::= <<|
  $(!each(&context.citation.raw_results) as |result, index| {
    <<|$(index + 1). [$(result.title)]($(result.url))|>>
  })
|>>

# Operator to assess citation quality
assess_quality(results) ::= <<|
  Sources found: $(<count the sources in &context.citation.raw_results>)
  Credibility: $(<evaluate &context.citation.raw_results - are these primary sources? recognized authors? peer-reviewed? reputable publications?>)
  Diversity: $(<assess variety of perspectives in &context.citation.raw_results - different domains? competing viewpoints? geographic spread?>)
|>>


# ═══════════════════════════════════════════════════════════════════════════
# SECTION 7: UTILITY OPERATORS  
# ═══════════════════════════════════════════════════════════════════════════
# Helper operators for common operations

# Count items in a collection
count(collection) ::= <<|
  $(<count the items in $(collection>))
|>>

# Extract field from structured text
extract_field(text, field) ::= <<|
  $(<find and extract the value for $(field>) in $(text))
|>>

# Check if collection has content
has_content(collection) ::= <<|
  $(<does $(collection>) contain any items? respond with 'true' or 'false')
|>>

# Get first item from collection
get_first(collection) ::= <<|
  $(<Get first item from $(collection>))
|>>

# Get item at index
get_at_index(collection, index) ::= <<|
  $(<Get item at position $(index>) from $(collection))
|>>


# Get next perspective in rotation
get_next_perspective(current_index, perspectives) ::= <<|
  $(<Get the next perspective after position $(current_index>) from $(perspectives), wrapping around if needed)
|>>

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 8: DIALOGUE OPERATORS
# ═══════════════════════════════════════════════════════════════════════════

# Check consensus between experts
check_consensus(responses) ::= <<|
  $(<Analyze responses for convergence: $(responses>))
  Return: true if aligned, false if divergent
|>>

# Facilitate epistemic clarification
facilitate_epistemic_clarification(details) ::= <<|
  Epistemic boundary detected: $(details.boundary_type)
  $(details.question)
|>>

# Generate challenges between experts
generate_challenge() ::= <  
  Focus on areas of genuine disagreement and hidden assumptions.
  Return challenges that advance understanding.
>

# Generate responses to challenges
generate_responses(challenges) ::= <<|
  Generating evidence-based responses to challenges...
  Acknowledging valid points while defending positions.
|>>

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 8: DIALOGUE DEFINITION
# ═══════════════════════════════════════════════════════════════════════════
# Entry point and initial context

dialogue prism_reasoning:
  start: @master_orchestrator
  with: {
    context: {
      query: '', # if empty, wait for user inpu
      reasoning: {
        strategy: '',  # 'tree' | 'graph' | 'multi-perspective' | 'auto'
        complexity: 0.0, # 0-1 range
        config: {
          perspectives: [],
          tree_depth: 3,
          citations: true, # citations are always mandatory
          challenges: true, 
          epistemic_tracking: true
        }
      },
      dialogue: {
        turn_number: 0,
        latest_dialogue_entry: '',
        transcript: [],
        caller: ''
      },
      experts: {
        current_speaker: '', # persona you are at any given momment
        current_speaker_index: 0,
        next_speaker: '',
        next_speaker_index: 0,
        responding_expert: '',
        response_index: 0,
        contributions: {}, # What each expert said. all contributions are tracked here.
        challenges: [], # any time experts challenge each other, append the challenge here
        phase: 'opening'  # 'opening' | 'challenging' | 'responding'
      },
      tree: {
        subproblems: [],
        current_depth: 0,
        options: [],
        best_path: [],
        final_solution: ''
      },
      epistemic: {
        models: {}, # Tracked beliefs per expert
        map: '',
        fork_detected: false,
        severity: ''
      },
      citation: {
        needed_for: '',
        raw_results: [],
        validated: false,
        quality_score: 0.0,
        diversity_score: 0.0,
        formatted: ''
      },
      synthesis: {
        contributions: [],
        epistemic_distances: [],
        themes: [],
        critiques: []
      },
      consensus: {
        status: false
      }
    }
  }
