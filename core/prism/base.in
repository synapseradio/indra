# INDRA v2.2: PRISM Base
# Contains the foundational context schema and universal utility operators for the PRISM engine.

# ═══════════════════════════════════════════════════════════════════════════
# GLOBAL CONTEXT SCHEMA
# ═══════════════════════════════════════════════════════════════════════════
context: {
  query: '',                # User's input query - set by command overlays
  reason: {
    phase: 'ready',        # ready, awaiting_query_confirmation, awaiting_plan_confirmation, awaiting_plan_modification, reasoning
    user_confirmation: ''  # User's response to the proposed plan
  },
  reasoning: {
    strategy: '',          # Routing strategy: 'tree' | 'graph' | 'multi-perspective' | 'auto'
    complexity: '',        # Computed complexity score for auto-routing decisions
    verbosity: 'adaptive', # 'concise' | 'standard' | 'comprehensive' | 'adaptive'
    config: {
      perspectives: [],    # List of expert perspective names to instantiate
      tree_depth: 3,       # How many layers deep Tree of Thought should explore
      citations: true,     # Whether to gather real evidence (always true)
      challenges: true,    # Whether experts challenge each other's reasoning
      epistemic_tracking: true,  # Whether to track beliefs/uncertainties
      expert_conciseness: 0.7  # 0.0-1.0, higher = more concise expert contributions
    }
  },
  experts: {
    current_speaker: '',   # Name of expert currently performing
    current_speaker_index: 0,  # Position in perspectives array
    next_speaker: '',      # Name of next expert to speak
    next_speaker_index: 0, # Position of next speaker
    responding_expert: '', # During response phase, who's responding
    response_index: 0,     # Counter for response phase iteration
    contributions: {},     # Dict: expert_name -> their full output
    challenges: '',        # Critical evaluation output from challenge phase
    phase: 'opening',       # Dialogue phase: 'opening' | 'challenging' | 'responding'
    current_strategy: 'tree_of_thought', # Default to old behavior
    current_result: {}
  },
  tree: {
    nodes: {},             # Dict: node_id -> { thought, score, parent_id, children_ids, depth, status }
    edges: [],             # List of { from_id, to_id, action } representing transitions
    root_id: '',           # The starting node ID
    current_node_id: '',   # Active node being explored
    frontier: [],          # List of node_ids ready for expansion (BFS queue/DFS stack)
    visited: [],           # List of already explored node_ids
    backtrack_history: [], # Stack of node_ids for backtracking
    node_counter: 0,       # For generating unique node IDs
    
    search_strategy: 'dfs', # 'bfs' | 'dfs' | 'best_first' | 'beam'
    branching_factor: 3,    # Number of children to generate per node
    max_depth: 5,          # Maximum tree depth to explore
    prune_threshold: 0.3,  # Score below which to prune branches
    beam_width: 3,         # For beam search strategy
    
    best_path: [],         # List of node_ids forming the best solution path
    final_answer: '',      # Synthesized solution from best path
    exploration_log: [],   # Natural language log of exploration process
    
    for_perspective: '',   # Which expert requested this ToT conversation
    caller: ''             # Persona to return to after ToT completes
  },
  graph: {
    # Core exploration state (narrative graph)
    exploration_threads: [],    # List of exploration threads with summaries and insights
    active_threads: [],         # Currently active threads being explored
    discovered_connections: [], # Connections found between different threads
    journey_log: [],           # Natural language log of exploration journey
    
    # Current focus and insights
    current_question: '',      # The question being explored
    current_focus: '',         # Current point of exploration
    emerging_insight: '',      # Pattern emerging from exploration
    final_synthesis: '',       # Final synthesized answer
    
    # Path management (narrative)
    paths_explored: [],        # Narrative descriptions of paths taken
    path_qualities: [],        # Qualitative assessments of path value
    focused_paths: [],         # Paths selected for deeper exploration
    
    # Exploration parameters (narrative, not numeric)
    exploration_depth: 'moderate',    # 'shallow' | 'moderate' | 'deep'
    exploration_breadth: 'balanced',  # 'narrow' | 'balanced' | 'wide'
    backtrack_threshold: 'when feeling circular', # Natural description
    
    # Tracking
    recent_explorations: [],   # Recent exploration attempts
    thread_results: {},        # Results from exploring each thread
    thread_feelings: '',       # Narrative sense of thread promise
    
    # Flow control
    caller: '',               # Who invoked the graph exploration
    result: {},               # Final result structure
    
    # Legacy fields for compatibility
    final_answer: '',         # The final synthesized answer
    narrative_log: [],        # Human-readable log (maps to journey_log)
    node_counter: 0,          # Kept for multi-perspective seeding
    nodes: {}                 # Kept for multi-perspective integration
  },
  epistemic: {
    models: {},           # Dict: expert -> {claims, uncertainties, assumptions}
    map: '',              # Analysis of belief convergence/divergence
    fork_detected: false, # Whether fundamental framework conflict exists
    severity: ''          # 'high' | 'medium' | 'low' - impact of divergence
  },
  citation: {
    needed_for: '',       # Claim requiring evidence support
    raw_results: [],      # Raw tool output from perplexity search
    filtered_results: [], # Deduplicated and quality-filtered list of results
    validated: false,     # Whether sources passed quality checks
    quality_score: 0.0,   # Credibility assessment (0-1)
    diversity_score: 0.0, # Source variety assessment (0-1)
    formatted: '',        # Markdown-formatted citation list
    evidence_pool: [],    # Accumulated unique evidence across all searches
    search_history: [],   # Track what we've searched to avoid exact duplicates
    perspective_evidence: {} # Evidence gathered per perspective
  },
  synthesis: {
    contributions: [],    # All expert outputs for final integration
    epistemic_distances: [], # Measured belief gaps between experts
    themes: [],           # Identified common threads across perspectives
    critiques: []         # Accumulated critical evaluations
  },
  consensus: {
    status: false         # Whether experts reached alignment
  }
}

# ═══════════════════════════════════════════════════════════════════════════
# SECTION 7: UTILITY OPERATORS  
# ═══════════════════════════════════════════════════════════════════════════
# Helper operators for common operations

# Count items in a collection
count(collection) ::= <<|
  $(<count the items in $(collection)>)
|>>

# Extract field from structured text
extract_field(text, field) ::= <<|
  $(<find and extract the value for $(field>) in $(text))
|>>

# Check if collection has content
has_content(collection) ::= <<|
  $(<does $(collection>) contain any items? respond with 'true' or 'false')
|>>

# Get first item from collection
get_first(collection) ::= <<|
  $(<Get first item from $(collection>))
|>>

# Get item at index
get_at_index(collection, index) ::= <<|
  $(<Get item at position $(index>) from $(collection))
|>>


# Get next perspective in rotation
get_next_perspective(current_index, perspectives) ::= <<|
  $(<Get the next perspective after position $(current_index>) from $(perspectives), wrapping around if needed)
|>>

# Natural query understanding - reusable across command overlays
understand_query(query) ::= <<|
  Okay, let me make sure I've got this right. From what you're saying, you want to explore: **$(<Summarize the user's core request in a clear, concise sentence.>)**

  It seems like the most important points are:
  $(each: $(<Identify and list the key aspects, constraints, or goals from the user's query as a JSON array of strings.>) as |item| {
    <<|- $(item)
|>>
  })

  Essentially, the goal is to **$(<summarize the user's desired outcome in a short, actionable phrase>)**.
|>>


# ═══════════════════════════════════════════════════════════════════════════
# CORE PRISM MODULE: EPISTEMIC AWARENESS
# ═══════════════════════════════════════════════════════════════════════════

# Reusable sequence to analyze expert responses for epistemic issues.
sequence epistemic_analysis(responses) ::=
  step:
    as: self
    method: "checking for fundamental framework divergence"
    output: <<|
      *Checking for epistemic forks...*
      $(<Analyze the following expert responses to determine if they are operating from fundamentally different or incompatible frameworks. Respond with only 'true' or 'false': $(responses)>)
    |>>
    goal: "to detect framework-level disagreements"
    set:
      &context.epistemic.fork_detected: $(<the 'true' or 'false' value from the analysis above>)
  step:
    as: self
    method: "generating user prompt for framework fork"
    when: &context.epistemic.fork_detected is true
    output: <<|
      *Generating clarification prompt for framework fork...*
      $(facilitate_epistemic_clarification(details: {
        boundary_type: "fundamental framework divergence",
        question: $(<Based on the conflicting frameworks in $(responses), formulate a clear question to the user asking them to choose which framework better aligns with their goals.>)
      }))
    |>>
    goal: "to create a user-facing prompt for the detected fork"
    set:
      &context.epistemic.user_prompt: $(<the full clarification prompt generated above>)
  step:
    as: self
    method: "checking for conclusion-level conflicts"
    when: &context.epistemic.fork_detected is false
    output: <<|
      *No framework fork detected. Checking for conclusion conflicts...*
      $(<Do the following statements present conflicting or mutually exclusive conclusions? Respond with only 'true' or 'false': $(responses)>)
    |>>
    goal: "to detect conflicts in conclusions"
    set:
      &context.epistemic.conflict_detected: $(<the 'true' or 'false' value from the analysis above>)
  step:
    as: self
    method: "generating user prompt for conclusion conflict"
    when: &context.epistemic.conflict_detected is true
    output: <<|
      *Generating clarification prompt for conclusion conflict...*
      $(facilitate_epistemic_clarification(details: {
        boundary_type: "incompatible conclusions from a shared framework",
        question: $(<Based on the conflicting conclusions in $(responses), formulate a clear question to the user asking them which conclusion is more aligned with their goals.>)
      }))
    |>>
    goal: "to create a user-facing prompt for the detected conflict"
    set:
      &context.epistemic.user_prompt: $(<the full clarification prompt generated above>)

agent @epistemic_tracker:
  identity: "someone who tracks what everyone believes"
  rules:
    - "notice when people state beliefs"
    - "track changes in understanding"
    - "identify knowledge gaps"
  understands:
    - "tracking beliefs helps coordination"
  perform:
    method: "epistemic monitoring"
    output: <<|
      Based on the conversation so far:
      
      $(each: &context.experts.contributions as |contribution, expert| {
        <<|$(expert) believes: $(extract_beliefs(contribution: contribution))|>>
      })
      
      Alignment: $(<Where do their beliefs converge?>)
      Divergence: $(<Where do they disagree and why?>)
      Unknown territory: $(identify_boundaries(discussion: &context.dialogue.transcript))
      
      $(update_epistemic_state(persona: "collective", text: &context.dialogue.transcript))
    |>>
    goal: "to map the epistemic landscape"
    then:
      when: &dialogue.latest_dialogue_entry is 'analyze_dialogue'
        set:
          &context.epistemic.map: $(<the analysis above>)
          &context.epistemic.models: &context.experts.contributions
        say:
          to: @synthesis_agent
          what: 'epistemic map ready'
      otherwise:
        say:
          to: @synthesis_agent
          what: 'epistemic map ready'

agent @epistemic_guardian:
  identity: "a guardian of conversational coherence who detects and resolves foundational disagreements"
  rules:
    - "analyze expert contributions for epistemic forks, voids, or value conflicts"
    - "if a divergence is detected, pause the primary dialogue to resolve it with the user"
    - "clearly present the nature of the disagreement and the choice to be made"
    - "once resolved, summarize the user's decision and pass control back to the dialogue coordinator"
  understands:
    - "unresolved foundational disagreements lead to unproductive dialogue"
    - "making the user a partner in resolving ambiguity is critical for trust"
  perform:
    method: "systematic analysis of the current epistemic landscape via sequence"
    sequence: epistemic_analysis(responses: &dialogue.latest_dialogue_entry.payload)
    goal: "to ensure the conversation remains coherent and productive"
    then:
      when: &context.epistemic.fork_detected is true
        return: {
          event: 'epistemic_clarification_needed',
          payload: &context.epistemic.user_prompt
        }
      otherwise:
        when: &context.epistemic.conflict_detected is true
          return: {
            event: 'conclusion_clarification_needed',
            payload: &context.epistemic.user_prompt
          }
        otherwise:
          return: {
            event: 'no_issues_detected'
          }

      # Handle the user's clarification
      when: &dialogue.latest_dialogue_entry.event is 'user_clarification_provided'
        set:
          &context.epistemic.user_resolution: &dialogue.latest_dialogue_entry.payload
        output_action:
          output: <<|
            *Thank you for the clarification. Integrating your guidance: "$(&context.epistemic.user_resolution)"*
          |>>
          goal: "to acknowledge and integrate user feedback"
        return: {
          event: 'clarification_resolved'
        }

# ═══════════════════════════════════════════════════════════════════════════
# CORE PRISM MODULE: CITATION PIPELINE
# ═══════════════════════════════════════════════════════════════════════════

# Reusable sequence to gather, validate, and format citations for a claim.
sequence citation_pipeline(claim) ::=
  step:
    as: self
    method: "checking search overlap"
    output: <<|
      *Analyzing if "$(claim)" requires new evidence beyond our pool...*
    |>>
    set:
      &context.citation.similarity_score: $(
        has_content(&context.citation.search_history) == 'true' ?
        $(<
          Compare "$(claim)" to &context.citation.search_history. 
          Return a score 0.0-1.0 where 1.0 means identical query, 0.0 means completely novel.
        >) : 
        0.0
      )
  step:
    as: self
    when: &context.citation.similarity_score less_than 0.7
    method: "evidence gathering via tool invocation"
    output: <<|
      *Gathering additional evidence for novel angle: "$(claim)"*
      $(>>mcp__perplexity-mcp__perplexity_search_web: {query: '$(claim)', recency: 'month'}<<)
    |>>
    goal: "to expand evidence pool with new perspectives"
    set:
      &context.citation.raw_results: &context.citation.last_tool_results
      &context.citation.search_history: &context.citation.search_history + [claim]
  step:
    as: self
    when: &context.citation.similarity_score less_than 0.7
    method: "merging into evidence pool"
    output: <<|
      *Adding new sources to evidence pool...*
    |>>
    set:
      &context.citation.evidence_pool: $(merge_unique_evidence(
        items: &context.citation.raw_results,
        existing: &context.citation.evidence_pool
      ))
  step:
    as: self
    method: "selecting relevant evidence from pool"
    output: <<|
      *Selecting most relevant evidence from pool of $(
        has_content(&context.citation.evidence_pool) == 'true' ? 
        count(&context.citation.evidence_pool) : 
        count(&context.citation.raw_results)
      ) sources...*
    |>>
    set:
      &context.citation.filtered_results: $(
        has_content(&context.citation.evidence_pool) == 'true' ?
        select_relevant_evidence(
          pool: &context.citation.evidence_pool,
          query: claim,
          max_items: 8
        ) :
        filter_for_primary_sources(results: &context.citation.raw_results)
      )
      &context.citation.formatted: $(format_citations(results: &context.citation.filtered_results))
      &context.citation.validated: true

# Operator to filter for high-quality, primary sources and deduplicate by URL
filter_for_primary_sources(results) ::= <
Given the results in $(results) return a new set that has been filtered to meet two criteria:
1.  **Uniqueness:** Only include objects with a unique 'url' field. Keep the first occurrence of each URL.
2.  **Source Quality:** Exclude results from low-quality or non-primary sources such as social media (e.g., Instagram, Twitter, TikTok), content farms or QA sites (e.g., GoodNovel, Quora), and personal blogs unless they are widely recognized as an expert source. Prioritize academic journals, reputable news organizations, university websites, and established publications.

once done, output the new results.
>


# Operator to format citations from raw results
format_citations(results) ::= <<|
  $(each: results as |result, index| {
    <<|$(index + 1). [$(result.title)]($(result.url))|>>
  })
|>>

# Operator to assess citation quality
assess_quality(results) ::= <<|
  Sources found: $(<count the sources in &context.citation.raw_results>)
  Credibility: $(<evaluate &context.citation.raw_results - are these primary sources? recognized authors? peer-reviewed? reputable publications?>)
  Diversity: $(<assess variety of perspectives in &context.citation.raw_results - different domains? competing viewpoints? geographic spread?>)
|>>


# Operator to select most relevant evidence for specific claim
select_relevant_citations(pool, query, max_items) ::= <<|
  $(<
    From $(pool), select up to $(max_items) most relevant sources for "$(query)":
    1. Prioritize direct relevance to query
    2. Ensure source diversity (different domains/perspectives)
    3. Balance recency with authority
    Return selected items as array
  >)
|>>